{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:35.426047500Z",
     "start_time": "2023-07-21T21:39:34.950958100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T04:57:29.376042Z",
     "start_time": "2023-07-22T04:57:28.973960300Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# print(file_contents)  # Print the contents of the file\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241m.\u001B[39mloads(file_contents)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Process the JSON data here\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'json' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m     data \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(file_contents)\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# Process the JSON data here\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[43mjson\u001B[49m\u001B[38;5;241m.\u001B[39mJSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError decoding JSON:\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = 'Data/All_Data.json'\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_contents = f.read()\n",
    "        # print(file_contents)  # Print the contents of the file\n",
    "\n",
    "    data = json.loads(file_contents)\n",
    "    # Process the JSON data here\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Error decoding JSON:\", e)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: '{file_path}'\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:35.502601600Z",
     "start_time": "2023-07-21T21:39:35.459329200Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:35.585847Z",
     "start_time": "2023-07-21T21:39:35.482472100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug_id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>repo</th>\n",
       "      <th>reformed_query</th>\n",
       "      <th>bug_title</th>\n",
       "      <th>bug_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112599</td>\n",
       "      <td>[providers/bundles/org.eclipse.ecf.provider.xm...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>subject chat XMPP title updated updated xmpp u...</td>\n",
       "      <td>– [XMPP] Room subject does not get updated in...</td>\n",
       "      <td>When updated remotely by xmpp server title of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125572</td>\n",
       "      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>IConnectContext Message IConnection SOContaine...</td>\n",
       "      <td>– ECF Generic provider thread interlock</td>\n",
       "      <td>We see the following problem while running an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134483</td>\n",
       "      <td>[framework/bundles/org.eclipse.ecf/src/org/ecl...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>ExceptionInInitializerError eclipse eclipse ge...</td>\n",
       "      <td>– Standalone ClientApplication is breaks in l...</td>\n",
       "      <td>The standalone org.eclipse.ecf.provider.app.Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146622</td>\n",
       "      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>deserialize handleAsynchEvent processAsynch Bi...</td>\n",
       "      <td>– deserializeSharedObjectMessage with custom ...</td>\n",
       "      <td>when sending a instance of a custom Class in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147269</td>\n",
       "      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>Shared createObject ECF launching Group Win Cr...</td>\n",
       "      <td>– The \"send file\" functionality fails and lau...</td>\n",
       "      <td>&gt;&gt;&gt; Environment: WinXP + Java 1.5.0_06 + Eclip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bug_id                                       ground_truth repo  \\\n",
       "0  112599  [providers/bundles/org.eclipse.ecf.provider.xm...  ecf   \n",
       "1  125572  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n",
       "2  134483  [framework/bundles/org.eclipse.ecf/src/org/ecl...  ecf   \n",
       "3  146622  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n",
       "4  147269  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n",
       "\n",
       "                                      reformed_query  \\\n",
       "0  subject chat XMPP title updated updated xmpp u...   \n",
       "1  IConnectContext Message IConnection SOContaine...   \n",
       "2  ExceptionInInitializerError eclipse eclipse ge...   \n",
       "3  deserialize handleAsynchEvent processAsynch Bi...   \n",
       "4  Shared createObject ECF launching Group Win Cr...   \n",
       "\n",
       "                                           bug_title  \\\n",
       "0   – [XMPP] Room subject does not get updated in...   \n",
       "1            – ECF Generic provider thread interlock   \n",
       "2   – Standalone ClientApplication is breaks in l...   \n",
       "3   – deserializeSharedObjectMessage with custom ...   \n",
       "4   – The \"send file\" functionality fails and lau...   \n",
       "\n",
       "                                     bug_description  \n",
       "0  When updated remotely by xmpp server title of ...  \n",
       "1  We see the following problem while running an ...  \n",
       "2  The standalone org.eclipse.ecf.provider.app.Cl...  \n",
       "3  when sending a instance of a custom Class in a...  \n",
       "4  >>> Environment: WinXP + Java 1.5.0_06 + Eclip...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset_df into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:36.209431300Z",
     "start_time": "2023-07-21T21:39:35.523979600Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test\n",
    "train_df, test_df = train_test_split(dataset_df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:36.224654600Z",
     "start_time": "2023-07-21T21:39:36.210432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:36.298192Z",
     "start_time": "2023-07-21T21:39:36.225653200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug_id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>repo</th>\n",
       "      <th>reformed_query</th>\n",
       "      <th>bug_title</th>\n",
       "      <th>bug_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>58110</td>\n",
       "      <td>[java/org/apache/jasper/compiler/ErrorDispatch...</td>\n",
       "      <td>tomcat70</td>\n",
       "      <td>UTF JDT Wrapper JspCompilationContext size Def...</td>\n",
       "      <td>– JSP compiler points error to wrong line num...</td>\n",
       "      <td>Created attachment 32888 [details]\\nApache Tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>55656</td>\n",
       "      <td>[java/org/apache/catalina/startup/Catalina.jav...</td>\n",
       "      <td>tomcat70</td>\n",
       "      <td>patch realms Loader server thrown classes load...</td>\n",
       "      <td>– Server ClassLoader not used for Server crea...</td>\n",
       "      <td>Created attachment 30931 [details]\\nproposed p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>340338</td>\n",
       "      <td>[org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...</td>\n",
       "      <td>eclipse.jdt.ui</td>\n",
       "      <td>invoking overwrites select select Ctrl charAtB...</td>\n",
       "      <td>– [content assist] Proposal does not replace ...</td>\n",
       "      <td>3.1.\\nInserting a proposal does not replace th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>21792</td>\n",
       "      <td>[org.eclipse.jdt.launching/launching/org/eclip...</td>\n",
       "      <td>eclipse.jdt.debug</td>\n",
       "      <td>argument Duser arguments passed argument dir e...</td>\n",
       "      <td>– vm arguments ending with a backslash cause ...</td>\n",
       "      <td>When creating a launch configuration, if one s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>221019</td>\n",
       "      <td>[ui/org.eclipse.pde.core/src/org/eclipse/pde/i...</td>\n",
       "      <td>eclipse.pde.ui</td>\n",
       "      <td>bundle container entries Require Bug Bug class...</td>\n",
       "      <td>– Duplicated entries in classpath container</td>\n",
       "      <td>When a bundle is added as a Require-Bundle to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bug_id                                       ground_truth  \\\n",
       "2288   58110  [java/org/apache/jasper/compiler/ErrorDispatch...   \n",
       "2208   55656  [java/org/apache/catalina/startup/Catalina.jav...   \n",
       "1036  340338  [org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...   \n",
       "457    21792  [org.eclipse.jdt.launching/launching/org/eclip...   \n",
       "1530  221019  [ui/org.eclipse.pde.core/src/org/eclipse/pde/i...   \n",
       "\n",
       "                   repo                                     reformed_query  \\\n",
       "2288           tomcat70  UTF JDT Wrapper JspCompilationContext size Def...   \n",
       "2208           tomcat70  patch realms Loader server thrown classes load...   \n",
       "1036     eclipse.jdt.ui  invoking overwrites select select Ctrl charAtB...   \n",
       "457   eclipse.jdt.debug  argument Duser arguments passed argument dir e...   \n",
       "1530     eclipse.pde.ui  bundle container entries Require Bug Bug class...   \n",
       "\n",
       "                                              bug_title  \\\n",
       "2288   – JSP compiler points error to wrong line num...   \n",
       "2208   – Server ClassLoader not used for Server crea...   \n",
       "1036   – [content assist] Proposal does not replace ...   \n",
       "457    – vm arguments ending with a backslash cause ...   \n",
       "1530        – Duplicated entries in classpath container   \n",
       "\n",
       "                                        bug_description  \n",
       "2288  Created attachment 32888 [details]\\nApache Tom...  \n",
       "2208  Created attachment 30931 [details]\\nproposed p...  \n",
       "1036  3.1.\\nInserting a proposal does not replace th...  \n",
       "457   When creating a launch configuration, if one s...  \n",
       "1530  When a bundle is added as a Require-Bundle to ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:36.303268200Z",
     "start_time": "2023-07-21T21:39:36.240882500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1972, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:36.611921700Z",
     "start_time": "2023-07-21T21:39:36.255104500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:36.674421800Z",
     "start_time": "2023-07-21T21:39:36.611921700Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"ml6team/keyphrase-generation-t5-small-inspec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:36.950719Z",
     "start_time": "2023-07-21T21:39:36.627546100Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:36.966639Z",
     "start_time": "2023-07-21T21:39:36.954624300Z"
    }
   },
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.059363800Z",
     "start_time": "2023-07-21T21:39:36.966639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bug_id', 'ground_truth', 'repo', 'reformed_query', 'bug_title',\n",
       "       'bug_description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.091006Z",
     "start_time": "2023-07-21T21:39:36.984281900Z"
    }
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 20\n",
    "\n",
    "def preprocess_function(df):\n",
    "    # inputs = [prefix + doc for doc in df[\"bug_description\"]]\n",
    "    inputs = df[\"bug_description\"].tolist()\n",
    "    labels = df[\"reformed_query\"].tolist()\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
    "    model_inputs[\"labels\"] = tokenizer(labels, max_length=max_target_length, truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.122772800Z",
     "start_time": "2023-07-21T21:39:36.998290400Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_df = train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.122772800Z",
     "start_time": "2023-07-21T21:39:37.013925300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug_id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>repo</th>\n",
       "      <th>reformed_query</th>\n",
       "      <th>bug_title</th>\n",
       "      <th>bug_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>58110</td>\n",
       "      <td>[java/org/apache/jasper/compiler/ErrorDispatch...</td>\n",
       "      <td>tomcat70</td>\n",
       "      <td>UTF JDT Wrapper JspCompilationContext size Def...</td>\n",
       "      <td>– JSP compiler points error to wrong line num...</td>\n",
       "      <td>Created attachment 32888 [details]\\nApache Tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>55656</td>\n",
       "      <td>[java/org/apache/catalina/startup/Catalina.jav...</td>\n",
       "      <td>tomcat70</td>\n",
       "      <td>patch realms Loader server thrown classes load...</td>\n",
       "      <td>– Server ClassLoader not used for Server crea...</td>\n",
       "      <td>Created attachment 30931 [details]\\nproposed p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>340338</td>\n",
       "      <td>[org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...</td>\n",
       "      <td>eclipse.jdt.ui</td>\n",
       "      <td>invoking overwrites select select Ctrl charAtB...</td>\n",
       "      <td>– [content assist] Proposal does not replace ...</td>\n",
       "      <td>3.1.\\nInserting a proposal does not replace th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bug_id                                       ground_truth  \\\n",
       "2288   58110  [java/org/apache/jasper/compiler/ErrorDispatch...   \n",
       "2208   55656  [java/org/apache/catalina/startup/Catalina.jav...   \n",
       "1036  340338  [org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...   \n",
       "\n",
       "                repo                                     reformed_query  \\\n",
       "2288        tomcat70  UTF JDT Wrapper JspCompilationContext size Def...   \n",
       "2208        tomcat70  patch realms Loader server thrown classes load...   \n",
       "1036  eclipse.jdt.ui  invoking overwrites select select Ctrl charAtB...   \n",
       "\n",
       "                                              bug_title  \\\n",
       "2288   – JSP compiler points error to wrong line num...   \n",
       "2208   – Server ClassLoader not used for Server crea...   \n",
       "1036   – [content assist] Proposal does not replace ...   \n",
       "\n",
       "                                        bug_description  \n",
       "2288  Created attachment 32888 [details]\\nApache Tom...  \n",
       "2208  Created attachment 30931 [details]\\nproposed p...  \n",
       "1036  3.1.\\nInserting a proposal does not replace th...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.122772800Z",
     "start_time": "2023-07-21T21:39:37.059363800Z"
    }
   },
   "outputs": [],
   "source": [
    "sr = preprocess_function(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.138284200Z",
     "start_time": "2023-07-21T21:39:37.059363800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.232457400Z",
     "start_time": "2023-07-21T21:39:37.091006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[6357, 26, 11352, 3538, 10927, 784, 221, 5756, 7, 908, 24263, 3059, 2138, 834, 26346, 5, 4241, 3, 18, 848, 52, 127, 934, 5, 10500, 27, 15687, 12, 9268, 8, 336, 1205, 96, 121, 2493, 6, 11, 446, 4274, 2890, 699, 500, 3505, 12, 689, 381, 1713, 927, 84, 19, 337, 38, 8, 336, 1205, 2493, 5, 3636, 10, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 3, 2, 1454, 1741, 543, 543, 8532, 9886, 2423, 31, 6675, 371, 6039, 31, 738, 25160, 2423, 31, 6327, 87, 10500, 31, 1454, 3155, 3, 2, 1454, 1741, 543, 4830, 3274, 3, 31, 27578, 5, 13780, 5, 1935, 31, 3, 1454, 3155, 3, 2, 1454, 55, 22341, 794, 41, 61, 3, 2, 6792, 2, 17057, 3155, 570, 17057, 21486, 15, 7, 3274, 206, 195, 117, 3, 99, 41, 3350, 17057, 21486, 15, 7, 2423, 2423, 29, 83, 40, 1820, 9175, 570, 17057, 21486, 15, 7, 5, 7991, 9960, 2423, 2423, 632, 61, 1205, 96, 121, 117, 22341, 3, 7, 29979, 196, 1018, 371, 699, 3274, 206, 195, 117, 21, 41, 17057, 3735, 21486, 3, 10, 570, 17057, 21486, 15, 7, 61, 3, 2, 13751, 7, 29979, 196, 1018, 371, 699, 3274, 96, 6645, 18, 25982, 63, 18, 30536, 21486, 18, 121, 1768, 41, 11500, 53, 61, 30536, 21486, 1768, 96, 5, 102, 1725, 121, 117, 3, 2, 3, 12840, 109, 152, 19, 29979, 196, 1018, 371, 699, 5420, 343, 3274, 6136, 117, 3, 99, 41, 55, 41, 7, 29979, 196, 1018, 371, 699, 2423, 2423, 29, 83, 40, 1820, 9175, 3, 7, 29979, 196, 1018, 371, 699, 5, 159, 427, 1167, 17, 63, 9960, 61, 61, 3, 2, 3, 7, 29979, 196, 1018, 371, 699, 3274, 96, 8221, 7, 87, 121, 1768, 3, 7, 29979, 196, 1018, 371, 699, 117, 13751, 371, 699, 1042, 29979, 196, 1018, 3274, 126, 7344, 41, 12251, 5, 2782, 1649, 138, 345, 9, 189, 41, 7, 29979, 196, 1018, 371, 699, 61, 3670, 13751, 159, 29979, 196, 1018, 371, 699, 5420, 343, 3274, 1042, 29979, 196, 1018, 5, 12135, 7, 41, 3670, 3, 2, 1205, 41, 7, 29979, 196, 1018, 371, 699, 2423, 2423, 29, 83, 40, 1820, 9175, 3, 7, 29979, 196, 1018, 371, 699, 5, 159, 427, 1167, 17, 63, 9960, 61, 3, 58, 96, 121, 3, 10, 96, 2, 603, 122, 3, 7, 52, 75, 2423, 31, 121, 1768, 3, 7, 29979, 196, 1018, 371, 699, 1768, 96, 31, 87, 3155, 121, 117, 1205, 96, 121, 117, 13751, 100, 2493, 756, 56, 1137, 12, 51, 2138, 446, 12111, 29801, 500, 3505, 12, 689, 1713, 927, 2, 3378, 2, 299, 3, 99, 888, 48, 689, 139, 8, 756, 689, 6, 258, 29801, 56, 500, 3505, 12, 8, 269, 689, 381, 1713, 2773, 3, 2, 3, 1454, 3155, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 446, 4274, 2890, 699, 5763, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 683, 9, 4339, 26586, 10, 597, 179, 12, 2890, 699, 853, 21, 446, 4274, 10, 389, 3505, 6935, 44, 689, 10, 505, 16, 8, 3, 354, 7, 102, 1042, 10, 3, 87, 4377, 5, 354, 7, 102, 597, 60, 1836, 179, 1081, 305, 10, 3, 2, 431, 10, 6792, 2, 17057, 3155, 570, 17057, 21486, 15, 7, 3274, 206, 195, 117, 489, 10, 3, 99, 41, 3350, 17057, 21486, 15, 7, 2423, 2423, 29, 83, 40, 1820, 9175, 570, 17057, 21486, 15, 7, 5, 7991, 9960, 2423, 2423, 632, 61, 505, 10, 1205, 96, 536, 121, 117, 668, 10, 335, 10, 22341, 3, 7, 29979, 196, 1018, 371, 699, 3274, 206, 195, 117, 850, 10, 21, 41, 17057, 3735, 21486, 3, 10, 570, 17057, 21486, 15, 7, 61, 3, 19814, 6471, 15, 10, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 29509, 10575, 52, 127, 566, 232, 1171, 5, 27578, 75, 10575, 52, 127, 599, 29509, 10575, 52, 127, 566, 232, 1171, 5, 27578, 10, 17864, 61, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 10575, 52, 127, 23664, 144, 1703, 5, 27578, 75, 10575, 52, 127, 599, 10575, 52, 127, 23664, 144, 1703, 5, 27578, 10, 3420, 10938, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 683, 12111, 5890, 102, 173, 49, 5, 729, 49, 342, 21486, 599, 683, 12111, 5890, 102, 173, 49, 5, 27578, 10, 3707, 9120, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 4118, 11728, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 2469, 7256, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 3710, 6982, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 683, 7, 102, 5890, 102, 173, 257, 4302, 6327, 5, 7699, 699, 599, 683, 7, 102, 5890, 102, 173, 257, 4302, 6327, 5, 27578, 10, 4122, 12703, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 3473, 1655, 5, 683, 7, 102, 17598, 1655, 518, 5846, 883, 5, 5114, 599, 683, 7, 102, 17598, 1655, 518, 5846, 883, 5, 27578, 10, 2469, 12703, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 3473, 1655, 5, 683, 7, 102, 17598, 1655, 5, 5114, 683, 7, 102, 371, 699, 599, 683, 7, 102, 17598, 1655, 5, 27578, 10, 3288, 9120, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 1], [6357, 26, 11352, 604, 4271, 536, 784, 221, 5756, 7, 908, 4382, 7947, 366, 975, 18765, 2460, 5, 7134, 49, 16, 1712, 9, 8280, 5, 10401, 49, 3010, 28, 12256, 3, 6443, 9522, 7, 42, 15854, 7, 11, 70, 6002, 11573, 6, 3, 99, 273, 2287, 33, 356, 16, 2460, 5, 226, 51, 40, 3, 9, 3, 10077, 6392, 19, 3, 12618, 5, 37, 1053, 19, 18759, 222, 49, 338, 5150, 17598, 49, 31, 7, 4501, 434, 32, 9, 588, 11, 59, 2625, 4501, 434, 32, 9, 588, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 18495, 5, 28953, 53, 3, 9, 6384, 405, 59, 3601, 8, 1374, 2850, 3, 99, 132, 31, 7, 3, 9, 1801, 116, 16, 1621, 1765, 738, 2094, 5, 2300, 6320, 10, 1300, 356, 3, 31, 5890, 4788, 1575, 147, 17504, 7, 31, 1682, 43, 10, 3, 14817, 1454, 2, 14817, 3, 12186, 794, 9960, 3, 2, 22341, 3, 7, 117, 3, 7, 5, 2782, 279, 63, 1422, 9960, 117, 3, 2, 3, 14817, 1454, 2, 14817, 1877, 1738, 96, 2782, 121, 2853, 205, 17, 52, 40, 1220, 24722, 3594, 1738, 3, 31, 4059, 188, 17, 31, 11, 8722, 34, 3274, 15425, 3, 7, 5, 4059, 188, 17, 279, 63, 1422, 9960, 117, 262, 4, 345, 14196, 2326, 10, 3, 7, 5, 4059, 188, 17, 9960, 117, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [[412, 9164, 446, 12111, 22553, 883, 446, 7, 102, 5890, 102, 173, 257, 4302, 6327, 812, 3, 29509, 10575, 1], [7947, 15854, 7, 1815, 9, 588, 2460, 3, 12618, 2287, 4002, 49, 11352, 4002, 49, 18759, 222, 49, 1, 0], [16, 1621, 1765, 147, 17504, 7, 1738, 1738, 205, 17, 52, 40, 3, 4059, 188, 17, 279, 63, 1422, 1]]}\n"
     ]
    }
   ],
   "source": [
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.661677600Z",
     "start_time": "2023-07-21T21:39:37.091006Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_train_df = preprocess_function(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.677305500Z",
     "start_time": "2023-07-21T21:39:37.661677600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Inputs: [6357, 26, 11352, 3538, 10927, 784, 221, 5756, 7, 908, 24263, 3059, 2138, 834, 26346, 5, 4241, 3, 18, 848, 52, 127, 934, 5, 10500, 27, 15687, 12, 9268, 8, 336, 1205, 96, 121, 2493, 6, 11, 446, 4274, 2890, 699, 500, 3505, 12, 689, 381, 1713, 927, 84, 19, 337, 38, 8, 336, 1205, 2493, 5, 3636, 10, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 3, 2, 1454, 1741, 543, 543, 8532, 9886, 2423, 31, 6675, 371, 6039, 31, 738, 25160, 2423, 31, 6327, 87, 10500, 31, 1454, 3155, 3, 2, 1454, 1741, 543, 4830, 3274, 3, 31, 27578, 5, 13780, 5, 1935, 31, 3, 1454, 3155, 3, 2, 1454, 55, 22341, 794, 41, 61, 3, 2, 6792, 2, 17057, 3155, 570, 17057, 21486, 15, 7, 3274, 206, 195, 117, 3, 99, 41, 3350, 17057, 21486, 15, 7, 2423, 2423, 29, 83, 40, 1820, 9175, 570, 17057, 21486, 15, 7, 5, 7991, 9960, 2423, 2423, 632, 61, 1205, 96, 121, 117, 22341, 3, 7, 29979, 196, 1018, 371, 699, 3274, 206, 195, 117, 21, 41, 17057, 3735, 21486, 3, 10, 570, 17057, 21486, 15, 7, 61, 3, 2, 13751, 7, 29979, 196, 1018, 371, 699, 3274, 96, 6645, 18, 25982, 63, 18, 30536, 21486, 18, 121, 1768, 41, 11500, 53, 61, 30536, 21486, 1768, 96, 5, 102, 1725, 121, 117, 3, 2, 3, 12840, 109, 152, 19, 29979, 196, 1018, 371, 699, 5420, 343, 3274, 6136, 117, 3, 99, 41, 55, 41, 7, 29979, 196, 1018, 371, 699, 2423, 2423, 29, 83, 40, 1820, 9175, 3, 7, 29979, 196, 1018, 371, 699, 5, 159, 427, 1167, 17, 63, 9960, 61, 61, 3, 2, 3, 7, 29979, 196, 1018, 371, 699, 3274, 96, 8221, 7, 87, 121, 1768, 3, 7, 29979, 196, 1018, 371, 699, 117, 13751, 371, 699, 1042, 29979, 196, 1018, 3274, 126, 7344, 41, 12251, 5, 2782, 1649, 138, 345, 9, 189, 41, 7, 29979, 196, 1018, 371, 699, 61, 3670, 13751, 159, 29979, 196, 1018, 371, 699, 5420, 343, 3274, 1042, 29979, 196, 1018, 5, 12135, 7, 41, 3670, 3, 2, 1205, 41, 7, 29979, 196, 1018, 371, 699, 2423, 2423, 29, 83, 40, 1820, 9175, 3, 7, 29979, 196, 1018, 371, 699, 5, 159, 427, 1167, 17, 63, 9960, 61, 3, 58, 96, 121, 3, 10, 96, 2, 603, 122, 3, 7, 52, 75, 2423, 31, 121, 1768, 3, 7, 29979, 196, 1018, 371, 699, 1768, 96, 31, 87, 3155, 121, 117, 1205, 96, 121, 117, 13751, 100, 2493, 756, 56, 1137, 12, 51, 2138, 446, 12111, 29801, 500, 3505, 12, 689, 1713, 927, 2, 3378, 2, 299, 3, 99, 888, 48, 689, 139, 8, 756, 689, 6, 258, 29801, 56, 500, 3505, 12, 8, 269, 689, 381, 1713, 2773, 3, 2, 3, 1454, 3155, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 446, 4274, 2890, 699, 5763, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 683, 9, 4339, 26586, 10, 597, 179, 12, 2890, 699, 853, 21, 446, 4274, 10, 389, 3505, 6935, 44, 689, 10, 505, 16, 8, 3, 354, 7, 102, 1042, 10, 3, 87, 4377, 5, 354, 7, 102, 597, 60, 1836, 179, 1081, 305, 10, 3, 2, 431, 10, 6792, 2, 17057, 3155, 570, 17057, 21486, 15, 7, 3274, 206, 195, 117, 489, 10, 3, 99, 41, 3350, 17057, 21486, 15, 7, 2423, 2423, 29, 83, 40, 1820, 9175, 570, 17057, 21486, 15, 7, 5, 7991, 9960, 2423, 2423, 632, 61, 505, 10, 1205, 96, 536, 121, 117, 668, 10, 335, 10, 22341, 3, 7, 29979, 196, 1018, 371, 699, 3274, 206, 195, 117, 850, 10, 21, 41, 17057, 3735, 21486, 3, 10, 570, 17057, 21486, 15, 7, 61, 3, 19814, 6471, 15, 10, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 29509, 10575, 52, 127, 566, 232, 1171, 5, 27578, 75, 10575, 52, 127, 599, 29509, 10575, 52, 127, 566, 232, 1171, 5, 27578, 10, 17864, 61, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 10575, 52, 127, 23664, 144, 1703, 5, 27578, 75, 10575, 52, 127, 599, 10575, 52, 127, 23664, 144, 1703, 5, 27578, 10, 3420, 10938, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 683, 12111, 5890, 102, 173, 49, 5, 729, 49, 342, 21486, 599, 683, 12111, 5890, 102, 173, 49, 5, 27578, 10, 3707, 9120, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 4118, 11728, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 2469, 7256, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 3710, 6982, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 683, 7, 102, 5890, 102, 173, 257, 4302, 6327, 5, 7699, 699, 599, 683, 7, 102, 5890, 102, 173, 257, 4302, 6327, 5, 27578, 10, 4122, 12703, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 3473, 1655, 5, 683, 7, 102, 17598, 1655, 518, 5846, 883, 5, 5114, 599, 683, 7, 102, 17598, 1655, 518, 5846, 883, 5, 27578, 10, 2469, 12703, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 3473, 1655, 5, 683, 7, 102, 17598, 1655, 5, 5114, 683, 7, 102, 371, 699, 599, 683, 7, 102, 17598, 1655, 5, 27578, 10, 3288, 9120, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 1]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Labels: [412, 9164, 446, 12111, 22553, 883, 446, 7, 102, 5890, 102, 173, 257, 4302, 6327, 812, 3, 29509, 10575, 1]\n",
      "\n",
      "Example 2\n",
      "Inputs: [6357, 26, 11352, 604, 4271, 536, 784, 221, 5756, 7, 908, 4382, 7947, 366, 975, 18765, 2460, 5, 7134, 49, 16, 1712, 9, 8280, 5, 10401, 49, 3010, 28, 12256, 3, 6443, 9522, 7, 42, 15854, 7, 11, 70, 6002, 11573, 6, 3, 99, 273, 2287, 33, 356, 16, 2460, 5, 226, 51, 40, 3, 9, 3, 10077, 6392, 19, 3, 12618, 5, 37, 1053, 19, 18759, 222, 49, 338, 5150, 17598, 49, 31, 7, 4501, 434, 32, 9, 588, 11, 59, 2625, 4501, 434, 32, 9, 588, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Labels: [7947, 15854, 7, 1815, 9, 588, 2460, 3, 12618, 2287, 4002, 49, 11352, 4002, 49, 18759, 222, 49, 1, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the tokenized_train_df after calling preprocess_function on train_df\n",
    "\n",
    "# Print the first two examples in tokenized_train_df\n",
    "for i in range(2):\n",
    "    print(\"Example\", i+1)\n",
    "    print(\"Inputs:\", tokenized_train_df[\"input_ids\"][i])\n",
    "    print(\"Attention Mask:\", tokenized_train_df[\"attention_mask\"][i])\n",
    "    print(\"Labels:\", tokenized_train_df[\"labels\"][i])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:39:37.818746600Z",
     "start_time": "2023-07-21T21:39:37.677305500Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_test_df = preprocess_function(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T06:10:29.507779Z",
     "start_time": "2023-07-22T06:10:29.254388400Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\u001B[0;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForSeq2SeqLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_checkpoint)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-21T21:40:49.381677600Z",
     "start_time": "2023-07-21T21:40:49.360306900Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    # fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-07-22T06:20:21.404545500Z",
     "start_time": "2023-07-22T06:20:18.462422700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA (GPU) is available.\n",
      "Result on device: tensor([5., 7., 9.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")       # If GPU is available, use it\n",
    "    print(\"CUDA (GPU) is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")        # If GPU is not available, use CPU\n",
    "    print(\"CUDA (GPU) is not available. Using CPU instead.\")\n",
    "\n",
    "# Some test code to see if it's working\n",
    "x = torch.tensor([1.0, 2.0, 3.0], device=device)\n",
    "y = torch.tensor([4.0, 5.0, 6.0], device=device)\n",
    "z = x + y\n",
    "\n",
    "print(\"Result on device:\", z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-07-22T03:05:37.642835Z",
     "start_time": "2023-07-22T03:05:37.585840500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available:  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Cuda available: \", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mdevice_count())\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_device_name\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\torch\\cuda\\__init__.py:365\u001B[0m, in \u001B[0;36mget_device_name\u001B[1;34m(device)\u001B[0m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_name\u001B[39m(device: Optional[_device_t] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m    354\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Gets the name of a device.\u001B[39;00m\n\u001B[0;32m    355\u001B[0m \n\u001B[0;32m    356\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    363\u001B[0m \u001B[38;5;124;03m        str: the name of the device\u001B[39;00m\n\u001B[0;32m    364\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_device_properties\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mname\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\torch\\cuda\\__init__.py:395\u001B[0m, in \u001B[0;36mget_device_properties\u001B[1;34m(device)\u001B[0m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_device_properties\u001B[39m(device: _device_t) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _CudaDeviceProperties:\n\u001B[0;32m    386\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Gets the properties of a device.\u001B[39;00m\n\u001B[0;32m    387\u001B[0m \n\u001B[0;32m    388\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001B[39;00m\n\u001B[0;32m    394\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 395\u001B[0m     \u001B[43m_lazy_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# will define _get_device_properties\u001B[39;00m\n\u001B[0;32m    396\u001B[0m     device \u001B[38;5;241m=\u001B[39m _get_device_index(device, optional\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    397\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m device_count():\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\torch\\cuda\\__init__.py:239\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    236\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T06:12:14.339433700Z",
     "start_time": "2023-07-22T06:12:14.061660300Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

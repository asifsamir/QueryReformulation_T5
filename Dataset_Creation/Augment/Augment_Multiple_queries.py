# this is to augment the dataset with multiple queries
# for each bug report, we will have multiple queries
# the queries are generated by replacing the words in the bug report with the words in the thesaurus
# match the steps from the ipynb file

import pandas as pd
import os
import json

base_path = 'D:\Research\Data\QueryReformulaiton\Forgotten_rule_query_reformulation-master\\'
ground_truth_path = base_path + '\GroundTruth'
reformulated_query_path = base_path + 'NrOptimal-GA\Query'
bug_report_path = base_path + '\BugReports\ALL'

# read folder names from bug report folder
bug_report_folders = os.listdir(bug_report_path)

bug_repos = bug_report_folders

#iteration will begin from here
# match the steps from the ipynb file

## Step: 1 first dataframe with bug_id and ground truth

# iterate over bug_repos and read the ground truth files
ground_truth_df = pd.DataFrame(columns=['bug_id', 'ground_truth', 'repo'])
for repo in bug_repos:
    cur_repo_path = ground_truth_path + '\\' + repo
    ground_truth_files = os.listdir(cur_repo_path)
    for file in ground_truth_files:
        cur_file_path = cur_repo_path + '\\' + file
        bug_id, _ = os.path.splitext(file)
        # read the content of the file as a string as ground truth
        with open(cur_file_path, 'r') as f:
            # one bug can have multiple ground truths. each line is a ground truth. read line wise add to a list
            ground_truth = f.readlines()
            # remove the new line character from the end of each line
            ground_truth = [x.strip() for x in ground_truth]


        # Creating a new DataFrame for the new row
        new_row = pd.DataFrame({'bug_id': [bug_id], 'ground_truth': [ground_truth], 'repo': [repo]})

        # Concatenate the new row DataFrame with the existing DataFrame
        ground_truth_df = pd.concat([ground_truth_df, new_row], ignore_index=True)


## Step-2: Second dataframe with bug_id and reformulated query
# iterate over bug_repos and read the ground truth files

all_reformed_query_files = os.listdir(reformulated_query_path)
dict_bug_id_query = {}
all_reformed_query_list = []

which_file = 'GA-ALL-QE-K10-1.txt'
reformed_query_df = pd.DataFrame(columns=['bug_id', 'reformed_query', 'repo'])
for repo in bug_repos:
    cur_query_file = reformulated_query_path + '\\' + repo + '\\' + which_file
    # read the file line by line. each line first few characters are the bug id separated by a tab; then the query
    with open(cur_query_file, 'r') as f:
        for line in f:
            bug_id = line.split('\t')[0]
            query = line.split('\t')[1]
            # remove the new line character from the end of each line
            query = query.strip()

            # Creating a new DataFrame for the new row
            new_row = pd.DataFrame({'bug_id': [bug_id], 'reformed_query': [query], 'repo': [repo]})

            # Concatenate the new row DataFrame with the existing DataFrame
            reformed_query_df = pd.concat([reformed_query_df, new_row], ignore_index=True)





## Step-3: Third dataframe with bug_id and bug report
# iterate over bug_repos and read the ground truth files
bug_report_df = pd.DataFrame(columns=['bug_id', 'bug_title', 'bug_description', 'repo'])
for repo in bug_repos:
    cur_repo_path = bug_report_path + '\\' + repo
    bug_report_files = os.listdir(cur_repo_path)
    for file in bug_report_files:
        cur_file_path = cur_repo_path + '\\' + file
        bug_id, _ = os.path.splitext(file)
        # read the content of the file as a string as ground truth
        with open(cur_file_path, 'r') as f:
            bug_title = f.readline()
            # remove the new line character from the end of each line
            bug_title = bug_title.strip()

            # replace the string format 'Bug+space+bug_id' from the beginning of the title
            bug_title = bug_title.replace('Bug ' + bug_id, '')
            bug_title = bug_title.replace(bug_id, '')

            bug_description = f.read()

        # Creating a new DataFrame for the new row
        new_row = pd.DataFrame({'bug_id': [bug_id], 'bug_title': [bug_title], 'bug_description': [bug_description], 'repo': [repo]})

        # Concatenate the new row DataFrame with the existing DataFrame
        bug_report_df = pd.concat([bug_report_df, new_row], ignore_index=True)



# ## Step 4: Merge the three dataframes
# # merge the three dataframes based on 'bug_id'
# merged_df = pd.merge(ground_truth_df, reformed_query_df, on=['bug_id', 'repo'])
#
# merged_df = pd.merge(merged_df, bug_report_df, on=['bug_id', 'repo'])
#
# merged_df.head()
#
#
# ## Step 5: Save the merged dataframe as a json file
# merged_df_dict = merged_df.to_dict('records')
#
# # save the list of dictionaries as a json file
# with open('Data/All_Data.json', 'w') as f:
#     json.dump(merged_df_dict, f)
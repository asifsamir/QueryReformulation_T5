{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:07.369186500Z",
     "start_time": "2023-07-23T18:07:06.563415900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:07.407334600Z",
     "start_time": "2023-07-23T18:07:07.372186Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = '../Data/All_Data.json'\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_contents = f.read()\n",
    "        # print(file_contents)  # Print the contents of the file\n",
    "\n",
    "    data = json.loads(file_contents)\n",
    "    # Process the JSON data here\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Error decoding JSON:\", e)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: '{file_path}'\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:07.415343600Z",
     "start_time": "2023-07-23T18:07:07.404334600Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:07.446858700Z",
     "start_time": "2023-07-23T18:07:07.420349800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   bug_id                                       ground_truth repo  \\\n0  112599  [providers/bundles/org.eclipse.ecf.provider.xm...  ecf   \n1  125572  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n2  134483  [framework/bundles/org.eclipse.ecf/src/org/ecl...  ecf   \n3  146622  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n4  147269  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n\n                                      reformed_query  \\\n0  subject chat XMPP title updated updated xmpp u...   \n1  IConnectContext Message IConnection SOContaine...   \n2  ExceptionInInitializerError eclipse eclipse ge...   \n3  deserialize handleAsynchEvent processAsynch Bi...   \n4  Shared createObject ECF launching Group Win Cr...   \n\n                                           bug_title  \\\n0   – [XMPP] Room subject does not get updated in...   \n1            – ECF Generic provider thread interlock   \n2   – Standalone ClientApplication is breaks in l...   \n3   – deserializeSharedObjectMessage with custom ...   \n4   – The \"send file\" functionality fails and lau...   \n\n                                     bug_description  \n0  When updated remotely by xmpp server title of ...  \n1  We see the following problem while running an ...  \n2  The standalone org.eclipse.ecf.provider.app.Cl...  \n3  when sending a instance of a custom Class in a...  \n4  >>> Environment: WinXP + Java 1.5.0_06 + Eclip...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bug_id</th>\n      <th>ground_truth</th>\n      <th>repo</th>\n      <th>reformed_query</th>\n      <th>bug_title</th>\n      <th>bug_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>112599</td>\n      <td>[providers/bundles/org.eclipse.ecf.provider.xm...</td>\n      <td>ecf</td>\n      <td>subject chat XMPP title updated updated xmpp u...</td>\n      <td>– [XMPP] Room subject does not get updated in...</td>\n      <td>When updated remotely by xmpp server title of ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>125572</td>\n      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n      <td>ecf</td>\n      <td>IConnectContext Message IConnection SOContaine...</td>\n      <td>– ECF Generic provider thread interlock</td>\n      <td>We see the following problem while running an ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>134483</td>\n      <td>[framework/bundles/org.eclipse.ecf/src/org/ecl...</td>\n      <td>ecf</td>\n      <td>ExceptionInInitializerError eclipse eclipse ge...</td>\n      <td>– Standalone ClientApplication is breaks in l...</td>\n      <td>The standalone org.eclipse.ecf.provider.app.Cl...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>146622</td>\n      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n      <td>ecf</td>\n      <td>deserialize handleAsynchEvent processAsynch Bi...</td>\n      <td>– deserializeSharedObjectMessage with custom ...</td>\n      <td>when sending a instance of a custom Class in a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>147269</td>\n      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n      <td>ecf</td>\n      <td>Shared createObject ECF launching Group Win Cr...</td>\n      <td>– The \"send file\" functionality fails and lau...</td>\n      <td>&gt;&gt;&gt; Environment: WinXP + Java 1.5.0_06 + Eclip...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset_df into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:08.808238200Z",
     "start_time": "2023-07-23T18:07:07.449860500Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test\n",
    "train_df, test_df = train_test_split(dataset_df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "valid_df, test_df = train_test_split(test_df, test_size=0.35, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:08.854024300Z",
     "start_time": "2023-07-23T18:07:08.815254100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:08.855025100Z",
     "start_time": "2023-07-23T18:07:08.840027400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:08.864535900Z",
     "start_time": "2023-07-23T18:07:08.854024300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      bug_id                                       ground_truth  \\\n2288   58110  [java/org/apache/jasper/compiler/ErrorDispatch...   \n2208   55656  [java/org/apache/catalina/startup/Catalina.jav...   \n1036  340338  [org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...   \n457    21792  [org.eclipse.jdt.launching/launching/org/eclip...   \n1530  221019  [ui/org.eclipse.pde.core/src/org/eclipse/pde/i...   \n\n                   repo                                     reformed_query  \\\n2288           tomcat70  UTF JDT Wrapper JspCompilationContext size Def...   \n2208           tomcat70  patch realms Loader server thrown classes load...   \n1036     eclipse.jdt.ui  invoking overwrites select select Ctrl charAtB...   \n457   eclipse.jdt.debug  argument Duser arguments passed argument dir e...   \n1530     eclipse.pde.ui  bundle container entries Require Bug Bug class...   \n\n                                              bug_title  \\\n2288   – JSP compiler points error to wrong line num...   \n2208   – Server ClassLoader not used for Server crea...   \n1036   – [content assist] Proposal does not replace ...   \n457    – vm arguments ending with a backslash cause ...   \n1530        – Duplicated entries in classpath container   \n\n                                        bug_description  \n2288  Created attachment 32888 [details]\\nApache Tom...  \n2208  Created attachment 30931 [details]\\nproposed p...  \n1036  3.1.\\nInserting a proposal does not replace th...  \n457   When creating a launch configuration, if one s...  \n1530  When a bundle is added as a Require-Bundle to ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bug_id</th>\n      <th>ground_truth</th>\n      <th>repo</th>\n      <th>reformed_query</th>\n      <th>bug_title</th>\n      <th>bug_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2288</th>\n      <td>58110</td>\n      <td>[java/org/apache/jasper/compiler/ErrorDispatch...</td>\n      <td>tomcat70</td>\n      <td>UTF JDT Wrapper JspCompilationContext size Def...</td>\n      <td>– JSP compiler points error to wrong line num...</td>\n      <td>Created attachment 32888 [details]\\nApache Tom...</td>\n    </tr>\n    <tr>\n      <th>2208</th>\n      <td>55656</td>\n      <td>[java/org/apache/catalina/startup/Catalina.jav...</td>\n      <td>tomcat70</td>\n      <td>patch realms Loader server thrown classes load...</td>\n      <td>– Server ClassLoader not used for Server crea...</td>\n      <td>Created attachment 30931 [details]\\nproposed p...</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>340338</td>\n      <td>[org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...</td>\n      <td>eclipse.jdt.ui</td>\n      <td>invoking overwrites select select Ctrl charAtB...</td>\n      <td>– [content assist] Proposal does not replace ...</td>\n      <td>3.1.\\nInserting a proposal does not replace th...</td>\n    </tr>\n    <tr>\n      <th>457</th>\n      <td>21792</td>\n      <td>[org.eclipse.jdt.launching/launching/org/eclip...</td>\n      <td>eclipse.jdt.debug</td>\n      <td>argument Duser arguments passed argument dir e...</td>\n      <td>– vm arguments ending with a backslash cause ...</td>\n      <td>When creating a launch configuration, if one s...</td>\n    </tr>\n    <tr>\n      <th>1530</th>\n      <td>221019</td>\n      <td>[ui/org.eclipse.pde.core/src/org/eclipse/pde/i...</td>\n      <td>eclipse.pde.ui</td>\n      <td>bundle container entries Require Bug Bug class...</td>\n      <td>– Duplicated entries in classpath container</td>\n      <td>When a bundle is added as a Require-Bundle to ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:08.925542400Z",
     "start_time": "2023-07-23T18:07:08.865535600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1972, 6)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Works"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation Module"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precision', 'code_eval', 'roc_auc', 'cuad', 'xnli', 'rouge', 'pearsonr', 'mse', 'super_glue', 'comet', 'cer', 'sacrebleu', 'mahalanobis', 'wer', 'competition_math', 'f1', 'recall', 'coval', 'mauve', 'xtreme_s', 'bleurt', 'ter', 'accuracy', 'exact_match', 'indic_glue', 'spearmanr', 'mae', 'squad', 'chrf', 'glue', 'perplexity', 'mean_iou', 'squad_v2', 'meteor', 'bleu', 'wiki_split', 'sari', 'frugalscore', 'google_bleu', 'bertscore', 'matthews_correlation', 'seqeval', 'trec_eval', 'rl_reliability', 'angelina-wang/directional_bias_amplification', 'cpllab/syntaxgym', 'kaggle/ai4code', 'codeparrot/apps_metric', 'mfumanelli/geometric_mean', 'poseval', 'brier_score', 'abidlabs/mean_iou', 'abidlabs/mean_iou2', 'giulio98/codebleu', 'mase', 'mape', 'smape', 'dvitel/codebleu', 'NCSOFT/harim_plus', 'JP-SystemsX/nDCG', 'Drunper/metrica_tesi', 'jpxkqx/peak_signal_to_noise_ratio', 'jpxkqx/signal_to_reconstruction_error', 'hpi-dhc/FairEval', 'nist_mt', 'lvwerra/accuracy_score', 'character', 'charcut_mt', 'ybelkada/cocoevaluate', 'harshhpareek/bertscore', 'posicube/mean_reciprocal_rank', 'bstrai/classification_report', 'omidf/squad_precision_recall', 'Josh98/nl2bash_m', 'BucketHeadP65/confusion_matrix', 'BucketHeadP65/roc_curve', 'yonting/average_precision_score', 'transZ/test_parascore', 'transZ/sbert_cosine', 'hynky/sklearn_proxy', 'unnati/kendall_tau_distance', 'r_squared', 'Viona/fuzzy_reordering', 'Viona/kendall_tau', 'lhy/hamming_loss', 'lhy/ranking_loss', 'Muennighoff/code_eval_octopack', 'yuyijiong/quad_match_score', 'Splend1dchan/cosine_similarity', 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics', 'Yeshwant123/mcc', 'transformersegmentation/segmentation_scores', 'sma2023/wil', 'chanelcolgate/average_precision', 'ckb/unigram', 'Felipehonorato/eer', 'manueldeprada/beer', 'tialaeMceryu/unigram', 'He-Xingwei/sari_metric', 'langdonholmes/cohen_weighted_kappa', 'fschlatt/ner_eval', 'hyperml/balanced_accuracy', 'brian920128/doc_retrieve_metrics', 'guydav/restrictedpython_code_eval', 'k4black/codebleu', 'Natooz/ece', 'ingyu/klue_mrc', 'Vipitis/shadermatch', 'unitxt/metric', 'gabeorlanski/bc_eval', 'mcnemar', 'exact_match', 'wilcoxon', 'kaleidophon/almost_stochastic_order', 'word_length', 'lvwerra/element_count', 'word_count', 'text_duplicates', 'perplexity', 'label_distribution', 'toxicity', 'regard', 'honest', 'ybelkada/toxicity', 'ronaldahmed/ccl_win', 'meg/perplexity', 'cakiki/tokens_per_byte', 'lsy641/distinct', 'vercontasta/ccl_win']\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from evaluate import load, list_evaluation_modules\n",
    "#list of metrics\n",
    "print(list_evaluation_modules())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:13.618898Z",
     "start_time": "2023-07-23T18:07:08.882537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "metric = load(\"bleu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:14.478981900Z",
     "start_time": "2023-07-23T18:07:13.620898400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationModule(name: \"bleu\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
      "Computes BLEU score of translated segments against one or more references.\n",
      "Args:\n",
      "    predictions: list of translations to score.\n",
      "    references: list of lists of or just a list of references for each translation.\n",
      "    tokenizer : approach used for tokenizing `predictions` and `references`.\n",
      "        The default tokenizer is `tokenizer_13a`, a minimal tokenization approach that is equivalent to `mteval-v13a`, used by WMT.\n",
      "        This can be replaced by any function that takes a string as input and returns a list of tokens as output.\n",
      "    max_order: Maximum n-gram order to use when computing BLEU score.\n",
      "    smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
      "Returns:\n",
      "    'bleu': bleu score,\n",
      "    'precisions': geometric mean of n-gram precisions,\n",
      "    'brevity_penalty': brevity penalty,\n",
      "    'length_ratio': ratio of lengths,\n",
      "    'translation_length': translation_length,\n",
      "    'reference_length': reference_length\n",
      "Examples:\n",
      "\n",
      "    >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
      "    >>> references = [\n",
      "    ...     [\"hello there general kenobi\", \"hello there!\"],\n",
      "    ...     [\"foo bar foobar\"]\n",
      "    ... ]\n",
      "    >>> bleu = evaluate.load(\"bleu\")\n",
      "    >>> results = bleu.compute(predictions=predictions, references=references)\n",
      "    >>> print(results[\"bleu\"])\n",
      "    1.0\n",
      "\"\"\", stored examples: 0)\n"
     ]
    }
   ],
   "source": [
    "print(metric)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:14.495079300Z",
     "start_time": "2023-07-23T18:07:14.480000500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'bleu': 1.0,\n 'precisions': [1.0, 1.0, 1.0, 1.0],\n 'brevity_penalty': 1.0,\n 'length_ratio': 1.0,\n 'translation_length': 8,\n 'reference_length': 8}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = [\"this is a test\", \"this is another test\"]\n",
    "test_true = [\"this is a test\", \"this is another test\"]\n",
    "metric.compute(predictions=test_pred, references=test_true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:15.606646800Z",
     "start_time": "2023-07-23T18:07:14.496092300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### transofrmers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:15.663777600Z",
     "start_time": "2023-07-23T18:07:15.606646800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    Text2TextGenerationPipeline,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:15.670777900Z",
     "start_time": "2023-07-23T18:07:15.621749600Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"ml6team/keyphrase-extraction-kbir-inspec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:16.520258200Z",
     "start_time": "2023-07-23T18:07:15.635958500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.16k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72cb5b5fc04c49ef83354eae84b9e51e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\asifs\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cc74ea707434669b93b964960f29074"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cf3a82cdfd74f0cac11f150f6adc00d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2ba7fd92bd14b0ba6b5578cf2dc61ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9048cd9d905540ebbdd2e523749c86cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:16.537400600Z",
     "start_time": "2023-07-23T18:07:16.521262300Z"
    }
   },
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\", \"Salesforce/codet5-small\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:16.580399500Z",
     "start_time": "2023-07-23T18:07:16.541400900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['bug_id', 'ground_truth', 'repo', 'reformed_query', 'bug_title',\n       'bug_description'],\n      dtype='object')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 20\n",
    "\n",
    "keyphrase_sep_token = ';'\n",
    "\n",
    "def preprocess_function(bug_description, reformed_query):\n",
    "    # Assuming you have the tokenizer initialized and named as 'tokenizer'\n",
    "\n",
    "    document_inputs = tokenizer(\n",
    "        bug_description,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_length,\n",
    "        return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "    )\n",
    "\n",
    "    keyphrases = reformed_query.split()\n",
    "\n",
    "    target_text = f\" {keyphrase_sep_token} \".join(keyphrases)\n",
    "    targets = tokenizer(\n",
    "        target_text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target_length,\n",
    "        return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "    )\n",
    "    labels = targets.input_ids  # Clone the input_ids tensor to create the labels\n",
    "    labels[labels == tokenizer.pad_token_id] = -100  # Set padding token to -100\n",
    "    labels = [label if label != tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "    model_inputs = {\n",
    "        \"input_ids\": document_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": document_inputs[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "    return model_inputs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:16.595400900Z",
     "start_time": "2023-07-23T18:07:16.555400700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:16.595400900Z",
     "start_time": "2023-07-23T18:07:16.580399500Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_df = train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:16.605402700Z",
     "start_time": "2023-07-23T18:07:16.586403700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      bug_id                                       ground_truth  \\\n2288   58110  [java/org/apache/jasper/compiler/ErrorDispatch...   \n2208   55656  [java/org/apache/catalina/startup/Catalina.jav...   \n1036  340338  [org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...   \n\n                repo                                     reformed_query  \\\n2288        tomcat70  UTF JDT Wrapper JspCompilationContext size Def...   \n2208        tomcat70  patch realms Loader server thrown classes load...   \n1036  eclipse.jdt.ui  invoking overwrites select select Ctrl charAtB...   \n\n                                              bug_title  \\\n2288   – JSP compiler points error to wrong line num...   \n2208   – Server ClassLoader not used for Server crea...   \n1036   – [content assist] Proposal does not replace ...   \n\n                                        bug_description  \n2288  Created attachment 32888 [details]\\nApache Tom...  \n2208  Created attachment 30931 [details]\\nproposed p...  \n1036  3.1.\\nInserting a proposal does not replace th...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bug_id</th>\n      <th>ground_truth</th>\n      <th>repo</th>\n      <th>reformed_query</th>\n      <th>bug_title</th>\n      <th>bug_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2288</th>\n      <td>58110</td>\n      <td>[java/org/apache/jasper/compiler/ErrorDispatch...</td>\n      <td>tomcat70</td>\n      <td>UTF JDT Wrapper JspCompilationContext size Def...</td>\n      <td>– JSP compiler points error to wrong line num...</td>\n      <td>Created attachment 32888 [details]\\nApache Tom...</td>\n    </tr>\n    <tr>\n      <th>2208</th>\n      <td>55656</td>\n      <td>[java/org/apache/catalina/startup/Catalina.jav...</td>\n      <td>tomcat70</td>\n      <td>patch realms Loader server thrown classes load...</td>\n      <td>– Server ClassLoader not used for Server crea...</td>\n      <td>Created attachment 30931 [details]\\nproposed p...</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>340338</td>\n      <td>[org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...</td>\n      <td>eclipse.jdt.ui</td>\n      <td>invoking overwrites select select Ctrl charAtB...</td>\n      <td>– [content assist] Proposal does not replace ...</td>\n      <td>3.1.\\nInserting a proposal does not replace th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T18:07:18.486163Z",
     "start_time": "2023-07-23T18:07:16.601403400Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sr \u001B[38;5;241m=\u001B[39m [preprocess_function(row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbug_description\u001B[39m\u001B[38;5;124m\"\u001B[39m], row[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreformed_query\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m _, row \u001B[38;5;129;01min\u001B[39;00m temp_df\u001B[38;5;241m.\u001B[39miterrows()]\n",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sr \u001B[38;5;241m=\u001B[39m [\u001B[43mpreprocess_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbug_description\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreformed_query\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _, row \u001B[38;5;129;01min\u001B[39;00m temp_df\u001B[38;5;241m.\u001B[39miterrows()]\n",
      "Cell \u001B[1;32mIn[19], line 29\u001B[0m, in \u001B[0;36mpreprocess_function\u001B[1;34m(bug_description, reformed_query)\u001B[0m\n\u001B[0;32m     27\u001B[0m labels \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39minput_ids  \u001B[38;5;66;03m# Clone the input_ids tensor to create the labels\u001B[39;00m\n\u001B[0;32m     28\u001B[0m labels[labels \u001B[38;5;241m==\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad_token_id] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m  \u001B[38;5;66;03m# Set padding token to -100\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m labels \u001B[38;5;241m=\u001B[39m [label \u001B[38;5;28;01mif\u001B[39;00m label \u001B[38;5;241m!=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad_token_id \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels]\n\u001B[0;32m     31\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: document_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: document_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m: labels,\n\u001B[0;32m     35\u001B[0m }\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_inputs\n",
      "Cell \u001B[1;32mIn[19], line 29\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     27\u001B[0m labels \u001B[38;5;241m=\u001B[39m targets\u001B[38;5;241m.\u001B[39minput_ids  \u001B[38;5;66;03m# Clone the input_ids tensor to create the labels\u001B[39;00m\n\u001B[0;32m     28\u001B[0m labels[labels \u001B[38;5;241m==\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad_token_id] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m  \u001B[38;5;66;03m# Set padding token to -100\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m labels \u001B[38;5;241m=\u001B[39m [label \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlabel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m label \u001B[38;5;129;01min\u001B[39;00m labels]\n\u001B[0;32m     31\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m: document_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m: document_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     34\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m: labels,\n\u001B[0;32m     35\u001B[0m }\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_inputs\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "sr = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in temp_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in train_df.iterrows()]\n",
    "test_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in test_df.iterrows()]\n",
    "valid_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in valid_df.iterrows()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "tokenized_datasets = {\n",
    "    'train': train_data,\n",
    "    'test': test_data,\n",
    "    'validation': valid_data\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust the batch size based on available GPU memory\n",
    "batch_size = 16\n",
    "\n",
    "# Set up the Seq2SeqTrainingArguments\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-T5_keyphrase\",  # Change the output directory name\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    # push_to_hub=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    # Extract a few results\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_results = trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "#\n",
    "# # Initialize tqdm progress bar\n",
    "# progress_bar = tqdm(total=training_args.num_train_epochs, desc=\"Epoch\")\n",
    "#\n",
    "# # Train the model with tqdm progress bar\n",
    "# for epoch in range(training_args.num_train_epochs):\n",
    "#     trainer.train()\n",
    "#     progress_bar.update(1)\n",
    "#\n",
    "# # Close the tqdm progress bar\n",
    "# progress_bar.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(\"Training Losses:\", train_results.training_loss)\n",
    "# print(\"Evaluation Metrics:\", train_results.metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_directory = \"../FineTunedModels/KBIR_keyphrase\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Save the trained model and configuration\n",
    "# trainer.save_model(output_directory)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(output_directory)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate with test data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "# test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # see output with test data\n",
    "# print(\"Evaluation Metrics:\", test_results.metrics)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print the actual output\n",
    "print(test_df.iloc[0][\"reformed_query\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "# Move the input tensor to the CPU\n",
    "input_ids = tokenizer(test_df.iloc[1][\"bug_description\"], return_tensors=\"pt\").input_ids.to('cpu')\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(input_ids, max_length=40, num_beams=10, early_stopping=True, top_k=50, num_return_sequences=5)\n",
    "\n",
    "# Decode and print the output\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(test_df.iloc[1][\"bug_description\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(test_df.iloc[1][\"reformed_query\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created attachment 24618 [details]\n",
      "Patch\n",
      "ApplicationContextFacade generates lots of \"Type safety: Unchecked cast ...\" warnings which are caused by the doPrivileged() method wrapper.\n",
      "These can be suppressed with the patch to follow.\n",
      "patch applicationcontextfacade ; type safety ; unchecked cast ; doprivileged() method wrapper\n",
      "5\n",
      "patch applicationcontextfacade ; type safety ; unchecked cast ; doprivileged() method wrapper\n",
      "patch applicationcontextFacade ; type safety ; unchecked cast ; doprivileged() method wrapper\n",
      "patch applicationcontextfacade ; type safety ; unchecked cast ; doPrivileged() method wrapper\n",
      "patch applicationcontextFacade ; type safety ; unchecked cast ; doPrivileged() method wrapper\n",
      "patch applicationcontextfacade ; type safety ; unchecked cast ; doprivileged() method wrapper ;\n"
     ]
    }
   ],
   "source": [
    "print(test_df.iloc[1][\"bug_description\"])\n",
    "input_ids = tokenizer(test_df.iloc[1][\"bug_description\"], return_tensors=\"pt\").input_ids\n",
    "output = model.generate(input_ids, max_length=40, num_beams=60, early_stopping=True, top_k=50, num_return_sequences=5)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "print(len(output))\n",
    "\n",
    "# iterate through output and print\n",
    "for i in range(len(output)):\n",
    "    print(tokenizer.decode(output[i], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T17:57:16.020069900Z",
     "start_time": "2023-07-23T17:57:12.274325800Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

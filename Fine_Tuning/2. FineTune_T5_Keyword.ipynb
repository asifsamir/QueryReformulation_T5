{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:37:15.824139400Z",
     "start_time": "2023-07-23T14:37:14.737745200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:14.277598900Z",
     "start_time": "2023-07-23T14:44:14.240732900Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = '../Data/All_Data.json'\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_contents = f.read()\n",
    "        # print(file_contents)  # Print the contents of the file\n",
    "\n",
    "    data = json.loads(file_contents)\n",
    "    # Process the JSON data here\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Error decoding JSON:\", e)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: '{file_path}'\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:16.809870400Z",
     "start_time": "2023-07-23T14:44:16.792881800Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:17.766653700Z",
     "start_time": "2023-07-23T14:44:17.709908100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug_id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>repo</th>\n",
       "      <th>reformed_query</th>\n",
       "      <th>bug_title</th>\n",
       "      <th>bug_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112599</td>\n",
       "      <td>[providers/bundles/org.eclipse.ecf.provider.xm...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>subject chat XMPP title updated updated xmpp u...</td>\n",
       "      <td>– [XMPP] Room subject does not get updated in...</td>\n",
       "      <td>When updated remotely by xmpp server title of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125572</td>\n",
       "      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>IConnectContext Message IConnection SOContaine...</td>\n",
       "      <td>– ECF Generic provider thread interlock</td>\n",
       "      <td>We see the following problem while running an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134483</td>\n",
       "      <td>[framework/bundles/org.eclipse.ecf/src/org/ecl...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>ExceptionInInitializerError eclipse eclipse ge...</td>\n",
       "      <td>– Standalone ClientApplication is breaks in l...</td>\n",
       "      <td>The standalone org.eclipse.ecf.provider.app.Cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146622</td>\n",
       "      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>deserialize handleAsynchEvent processAsynch Bi...</td>\n",
       "      <td>– deserializeSharedObjectMessage with custom ...</td>\n",
       "      <td>when sending a instance of a custom Class in a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147269</td>\n",
       "      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n",
       "      <td>ecf</td>\n",
       "      <td>Shared createObject ECF launching Group Win Cr...</td>\n",
       "      <td>– The \"send file\" functionality fails and lau...</td>\n",
       "      <td>&gt;&gt;&gt; Environment: WinXP + Java 1.5.0_06 + Eclip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bug_id                                       ground_truth repo   \n",
       "0  112599  [providers/bundles/org.eclipse.ecf.provider.xm...  ecf  \\\n",
       "1  125572  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n",
       "2  134483  [framework/bundles/org.eclipse.ecf/src/org/ecl...  ecf   \n",
       "3  146622  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n",
       "4  147269  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n",
       "\n",
       "                                      reformed_query   \n",
       "0  subject chat XMPP title updated updated xmpp u...  \\\n",
       "1  IConnectContext Message IConnection SOContaine...   \n",
       "2  ExceptionInInitializerError eclipse eclipse ge...   \n",
       "3  deserialize handleAsynchEvent processAsynch Bi...   \n",
       "4  Shared createObject ECF launching Group Win Cr...   \n",
       "\n",
       "                                           bug_title   \n",
       "0   – [XMPP] Room subject does not get updated in...  \\\n",
       "1            – ECF Generic provider thread interlock   \n",
       "2   – Standalone ClientApplication is breaks in l...   \n",
       "3   – deserializeSharedObjectMessage with custom ...   \n",
       "4   – The \"send file\" functionality fails and lau...   \n",
       "\n",
       "                                     bug_description  \n",
       "0  When updated remotely by xmpp server title of ...  \n",
       "1  We see the following problem while running an ...  \n",
       "2  The standalone org.eclipse.ecf.provider.app.Cl...  \n",
       "3  when sending a instance of a custom Class in a...  \n",
       "4  >>> Environment: WinXP + Java 1.5.0_06 + Eclip...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset_df into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:20.750052700Z",
     "start_time": "2023-07-23T14:44:19.812421100Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test\n",
    "train_df, test_df = train_test_split(dataset_df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:21.367257900Z",
     "start_time": "2023-07-23T14:44:21.352353600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "valid_df, test_df = train_test_split(test_df, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:22.182792200Z",
     "start_time": "2023-07-23T14:44:22.157782300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:22.820444300Z",
     "start_time": "2023-07-23T14:44:22.799443300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bug_id</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>repo</th>\n",
       "      <th>reformed_query</th>\n",
       "      <th>bug_title</th>\n",
       "      <th>bug_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>58110</td>\n",
       "      <td>[java/org/apache/jasper/compiler/ErrorDispatch...</td>\n",
       "      <td>tomcat70</td>\n",
       "      <td>UTF JDT Wrapper JspCompilationContext size Def...</td>\n",
       "      <td>– JSP compiler points error to wrong line num...</td>\n",
       "      <td>Created attachment 32888 [details]\\nApache Tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>55656</td>\n",
       "      <td>[java/org/apache/catalina/startup/Catalina.jav...</td>\n",
       "      <td>tomcat70</td>\n",
       "      <td>patch realms Loader server thrown classes load...</td>\n",
       "      <td>– Server ClassLoader not used for Server crea...</td>\n",
       "      <td>Created attachment 30931 [details]\\nproposed p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>340338</td>\n",
       "      <td>[org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...</td>\n",
       "      <td>eclipse.jdt.ui</td>\n",
       "      <td>invoking overwrites select select Ctrl charAtB...</td>\n",
       "      <td>– [content assist] Proposal does not replace ...</td>\n",
       "      <td>3.1.\\nInserting a proposal does not replace th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>21792</td>\n",
       "      <td>[org.eclipse.jdt.launching/launching/org/eclip...</td>\n",
       "      <td>eclipse.jdt.debug</td>\n",
       "      <td>argument Duser arguments passed argument dir e...</td>\n",
       "      <td>– vm arguments ending with a backslash cause ...</td>\n",
       "      <td>When creating a launch configuration, if one s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>221019</td>\n",
       "      <td>[ui/org.eclipse.pde.core/src/org/eclipse/pde/i...</td>\n",
       "      <td>eclipse.pde.ui</td>\n",
       "      <td>bundle container entries Require Bug Bug class...</td>\n",
       "      <td>– Duplicated entries in classpath container</td>\n",
       "      <td>When a bundle is added as a Require-Bundle to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bug_id                                       ground_truth   \n",
       "2288   58110  [java/org/apache/jasper/compiler/ErrorDispatch...  \\\n",
       "2208   55656  [java/org/apache/catalina/startup/Catalina.jav...   \n",
       "1036  340338  [org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...   \n",
       "457    21792  [org.eclipse.jdt.launching/launching/org/eclip...   \n",
       "1530  221019  [ui/org.eclipse.pde.core/src/org/eclipse/pde/i...   \n",
       "\n",
       "                   repo                                     reformed_query   \n",
       "2288           tomcat70  UTF JDT Wrapper JspCompilationContext size Def...  \\\n",
       "2208           tomcat70  patch realms Loader server thrown classes load...   \n",
       "1036     eclipse.jdt.ui  invoking overwrites select select Ctrl charAtB...   \n",
       "457   eclipse.jdt.debug  argument Duser arguments passed argument dir e...   \n",
       "1530     eclipse.pde.ui  bundle container entries Require Bug Bug class...   \n",
       "\n",
       "                                              bug_title   \n",
       "2288   – JSP compiler points error to wrong line num...  \\\n",
       "2208   – Server ClassLoader not used for Server crea...   \n",
       "1036   – [content assist] Proposal does not replace ...   \n",
       "457    – vm arguments ending with a backslash cause ...   \n",
       "1530        – Duplicated entries in classpath container   \n",
       "\n",
       "                                        bug_description  \n",
       "2288  Created attachment 32888 [details]\\nApache Tom...  \n",
       "2208  Created attachment 30931 [details]\\nproposed p...  \n",
       "1036  3.1.\\nInserting a proposal does not replace th...  \n",
       "457   When creating a launch configuration, if one s...  \n",
       "1530  When a bundle is added as a Require-Bundle to ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:23.850488400Z",
     "start_time": "2023-07-23T14:44:23.810491900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1972, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:31.215125900Z",
     "start_time": "2023-07-23T14:44:26.453792400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[39mimport\u001B[39;00m \u001B[39mevaluate\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[39mfrom\u001B[39;00m \u001B[39mevaluate\u001B[39;00m \u001B[39mimport\u001B[39;00m load, list_evaluation_modules\n\u001B[1;32m      3\u001B[0m \u001B[39m#list of metrics\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'evaluate'"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from evaluate import load, list_evaluation_modules\n",
    "#list of metrics\n",
    "print(list_evaluation_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:33.873901800Z",
     "start_time": "2023-07-23T14:44:32.955432200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metric = load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:35.296078900Z",
     "start_time": "2023-07-23T14:44:35.278078200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:37.755957100Z",
     "start_time": "2023-07-23T14:44:36.648135600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_pred = [\"this is a test\", \"this is another test\"]\n",
    "test_true = [\"this is a test\", \"this is another test\"]\n",
    "metric.compute(predictions=test_pred, references=test_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transofrmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:39.105406700Z",
     "start_time": "2023-07-23T14:44:39.086402300Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    Text2TextGenerationPipeline,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:45:07.505979300Z",
     "start_time": "2023-07-23T14:45:07.486984Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_checkpoint = \"ml6team/keyphrase-generation-t5-small-inspec\"\n",
    "model_checkpoint = \"ml6team/keyphrase-generation-t5-small-inspec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:45:09.426915900Z",
     "start_time": "2023-07-23T14:45:09.150232500Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:45:14.960052700Z",
     "start_time": "2023-07-23T14:45:14.946550700Z"
    }
   },
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\", \"Salesforce/codet5-small\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:45:17.670471100Z",
     "start_time": "2023-07-23T14:45:17.655957100Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:07:37.565769300Z",
     "start_time": "2023-07-23T16:07:37.550776200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 50\n",
    "\n",
    "keyphrase_sep_token = ';'\n",
    "\n",
    "def preprocess_function(bug_description, reformed_query):\n",
    "    # Assuming you have the tokenizer initialized and named as 'tokenizer'\n",
    "\n",
    "    document_inputs = tokenizer(\n",
    "        bug_description,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    keyphrases = reformed_query.split()\n",
    "\n",
    "    target_text = f\" {keyphrase_sep_token} \".join(keyphrases)\n",
    "    targets = tokenizer(\n",
    "        target_text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target_length,\n",
    "        return_tensors=\"pt\"  # Ensure PyTorch tensors are returned\n",
    "    )\n",
    "    labels = targets.input_ids  # Clone the input_ids tensor to create the labels\n",
    "    labels[labels == tokenizer.pad_token_id] = -100  # Set padding token to -100\n",
    "    labels = [label if label != tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "    model_inputs = {\n",
    "        \"input_ids\": document_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": document_inputs[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:07:38.355894600Z",
     "start_time": "2023-07-23T16:07:38.317896800Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_df = train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:07:39.131832200Z",
     "start_time": "2023-07-23T16:07:39.102834400Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:07:41.163699900Z",
     "start_time": "2023-07-23T16:07:41.144186100Z"
    }
   },
   "outputs": [],
   "source": [
    "sr = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in temp_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T15:10:54.042274400Z",
     "start_time": "2023-07-23T15:10:54.023674600Z"
    }
   },
   "outputs": [],
   "source": [
    "type(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T15:15:39.541167700Z",
     "start_time": "2023-07-23T15:15:39.518857800Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:14.224137500Z",
     "start_time": "2023-07-23T16:12:11.213115800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in train_df.iterrows()]\n",
    "test_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in test_df.iterrows()]\n",
    "valid_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in valid_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:14.274117100Z",
     "start_time": "2023-07-23T16:12:14.224137500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "tokenized_datasets = {\n",
    "    'train': train_data,\n",
    "    'test': test_data,\n",
    "    'validation': valid_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:18.150654Z",
     "start_time": "2023-07-23T16:12:17.265288700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:19.462065900Z",
     "start_time": "2023-07-23T16:12:19.419532900Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Adjust the batch size based on available GPU memory\n",
    "batch_size = 16\n",
    "\n",
    "# Set up the Seq2SeqTrainingArguments\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-T5_keyphrase\",  # Change the output directory name\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    # push_to_hub=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:21.432056400Z",
     "start_time": "2023-07-23T16:12:21.407209Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:24.802398600Z",
     "start_time": "2023-07-23T16:12:24.792400600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    # Extract a few results\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:27.141312400Z",
     "start_time": "2023-07-23T16:12:26.941127900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:47:17.545900700Z",
     "start_time": "2023-07-23T16:12:28.864958200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "#\n",
    "# # Initialize tqdm progress bar\n",
    "# progress_bar = tqdm(total=training_args.num_train_epochs, desc=\"Epoch\")\n",
    "#\n",
    "# # Train the model with tqdm progress bar\n",
    "# for epoch in range(training_args.num_train_epochs):\n",
    "#     trainer.train()\n",
    "#     progress_bar.update(1)\n",
    "#\n",
    "# # Close the tqdm progress bar\n",
    "# progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Training Losses:\", train_results.training_loss)\n",
    "# print(\"Evaluation Metrics:\", train_results.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T19:48:58.243745500Z",
     "start_time": "2023-07-22T19:48:58.217102600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "output_directory = \"../FineTunedModels/T5_keyphrase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Save the trained model and configuration\n",
    "trainer.save_model(output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T19:49:22.337628700Z",
     "start_time": "2023-07-22T19:49:21.058187500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "# test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# see output with test data\n",
    "# print(\"Evaluation Metrics:\", test_results.metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-22T19:54:35.199372800Z",
     "start_time": "2023-07-22T19:54:35.177538300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print the actual output\n",
    "print(test_df.iloc[0][\"reformed_query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T17:44:29.465155900Z",
     "start_time": "2023-07-23T17:44:27.515741400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "# Move the input tensor to the CPU\n",
    "input_ids = tokenizer(test_df.iloc[1][\"bug_description\"], return_tensors=\"pt\").input_ids.to('cpu')\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(input_ids, max_length=40, num_beams=10, early_stopping=True, top_k=50, num_return_sequences=5)\n",
    "\n",
    "# Decode and print the output\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T17:53:41.101951100Z",
     "start_time": "2023-07-23T17:53:41.090963800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(test_df.iloc[1][\"bug_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T17:54:36.615664200Z",
     "start_time": "2023-07-23T17:54:36.606659100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(test_df.iloc[1][\"reformed_query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T17:57:16.020069900Z",
     "start_time": "2023-07-23T17:57:12.274325800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(test_df.iloc[1][\"bug_description\"])\n",
    "input_ids = tokenizer(test_df.iloc[1][\"bug_description\"], return_tensors=\"pt\").input_ids\n",
    "output = model.generate(input_ids, max_length=40, num_beams=60, early_stopping=True, top_k=50, num_return_sequences=5)\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "print(len(output))\n",
    "\n",
    "# iterate through output and print\n",
    "for i in range(len(output)):\n",
    "    print(tokenizer.decode(output[i], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

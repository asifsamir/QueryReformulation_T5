{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:37:15.824139400Z",
     "start_time": "2023-07-23T14:37:14.737745200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:14.277598900Z",
     "start_time": "2023-07-23T14:44:14.240732900Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = '../Data/All_Data.json'\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_contents = f.read()\n",
    "        # print(file_contents)  # Print the contents of the file\n",
    "\n",
    "    data = json.loads(file_contents)\n",
    "    # Process the JSON data here\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Error decoding JSON:\", e)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: '{file_path}'\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:16.809870400Z",
     "start_time": "2023-07-23T14:44:16.792881800Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:17.766653700Z",
     "start_time": "2023-07-23T14:44:17.709908100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   bug_id                                       ground_truth repo  \\\n0  112599  [providers/bundles/org.eclipse.ecf.provider.xm...  ecf   \n1  125572  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n2  134483  [framework/bundles/org.eclipse.ecf/src/org/ecl...  ecf   \n3  146622  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n4  147269  [framework/bundles/org.eclipse.ecf.provider/sr...  ecf   \n\n                                      reformed_query  \\\n0  subject chat XMPP title updated updated xmpp u...   \n1  IConnectContext Message IConnection SOContaine...   \n2  ExceptionInInitializerError eclipse eclipse ge...   \n3  deserialize handleAsynchEvent processAsynch Bi...   \n4  Shared createObject ECF launching Group Win Cr...   \n\n                                           bug_title  \\\n0   – [XMPP] Room subject does not get updated in...   \n1            – ECF Generic provider thread interlock   \n2   – Standalone ClientApplication is breaks in l...   \n3   – deserializeSharedObjectMessage with custom ...   \n4   – The \"send file\" functionality fails and lau...   \n\n                                     bug_description  \n0  When updated remotely by xmpp server title of ...  \n1  We see the following problem while running an ...  \n2  The standalone org.eclipse.ecf.provider.app.Cl...  \n3  when sending a instance of a custom Class in a...  \n4  >>> Environment: WinXP + Java 1.5.0_06 + Eclip...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bug_id</th>\n      <th>ground_truth</th>\n      <th>repo</th>\n      <th>reformed_query</th>\n      <th>bug_title</th>\n      <th>bug_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>112599</td>\n      <td>[providers/bundles/org.eclipse.ecf.provider.xm...</td>\n      <td>ecf</td>\n      <td>subject chat XMPP title updated updated xmpp u...</td>\n      <td>– [XMPP] Room subject does not get updated in...</td>\n      <td>When updated remotely by xmpp server title of ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>125572</td>\n      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n      <td>ecf</td>\n      <td>IConnectContext Message IConnection SOContaine...</td>\n      <td>– ECF Generic provider thread interlock</td>\n      <td>We see the following problem while running an ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>134483</td>\n      <td>[framework/bundles/org.eclipse.ecf/src/org/ecl...</td>\n      <td>ecf</td>\n      <td>ExceptionInInitializerError eclipse eclipse ge...</td>\n      <td>– Standalone ClientApplication is breaks in l...</td>\n      <td>The standalone org.eclipse.ecf.provider.app.Cl...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>146622</td>\n      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n      <td>ecf</td>\n      <td>deserialize handleAsynchEvent processAsynch Bi...</td>\n      <td>– deserializeSharedObjectMessage with custom ...</td>\n      <td>when sending a instance of a custom Class in a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>147269</td>\n      <td>[framework/bundles/org.eclipse.ecf.provider/sr...</td>\n      <td>ecf</td>\n      <td>Shared createObject ECF launching Group Win Cr...</td>\n      <td>– The \"send file\" functionality fails and lau...</td>\n      <td>&gt;&gt;&gt; Environment: WinXP + Java 1.5.0_06 + Eclip...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset_df into train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:20.750052700Z",
     "start_time": "2023-07-23T14:44:19.812421100Z"
    }
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into train and test\n",
    "train_df, test_df = train_test_split(dataset_df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "valid_df, test_df = train_test_split(test_df, test_size=0.35, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:21.367257900Z",
     "start_time": "2023-07-23T14:44:21.352353600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:22.182792200Z",
     "start_time": "2023-07-23T14:44:22.157782300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:22.820444300Z",
     "start_time": "2023-07-23T14:44:22.799443300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      bug_id                                       ground_truth  \\\n2288   58110  [java/org/apache/jasper/compiler/ErrorDispatch...   \n2208   55656  [java/org/apache/catalina/startup/Catalina.jav...   \n1036  340338  [org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...   \n457    21792  [org.eclipse.jdt.launching/launching/org/eclip...   \n1530  221019  [ui/org.eclipse.pde.core/src/org/eclipse/pde/i...   \n\n                   repo                                     reformed_query  \\\n2288           tomcat70  UTF JDT Wrapper JspCompilationContext size Def...   \n2208           tomcat70  patch realms Loader server thrown classes load...   \n1036     eclipse.jdt.ui  invoking overwrites select select Ctrl charAtB...   \n457   eclipse.jdt.debug  argument Duser arguments passed argument dir e...   \n1530     eclipse.pde.ui  bundle container entries Require Bug Bug class...   \n\n                                              bug_title  \\\n2288   – JSP compiler points error to wrong line num...   \n2208   – Server ClassLoader not used for Server crea...   \n1036   – [content assist] Proposal does not replace ...   \n457    – vm arguments ending with a backslash cause ...   \n1530        – Duplicated entries in classpath container   \n\n                                        bug_description  \n2288  Created attachment 32888 [details]\\nApache Tom...  \n2208  Created attachment 30931 [details]\\nproposed p...  \n1036  3.1.\\nInserting a proposal does not replace th...  \n457   When creating a launch configuration, if one s...  \n1530  When a bundle is added as a Require-Bundle to ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bug_id</th>\n      <th>ground_truth</th>\n      <th>repo</th>\n      <th>reformed_query</th>\n      <th>bug_title</th>\n      <th>bug_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2288</th>\n      <td>58110</td>\n      <td>[java/org/apache/jasper/compiler/ErrorDispatch...</td>\n      <td>tomcat70</td>\n      <td>UTF JDT Wrapper JspCompilationContext size Def...</td>\n      <td>– JSP compiler points error to wrong line num...</td>\n      <td>Created attachment 32888 [details]\\nApache Tom...</td>\n    </tr>\n    <tr>\n      <th>2208</th>\n      <td>55656</td>\n      <td>[java/org/apache/catalina/startup/Catalina.jav...</td>\n      <td>tomcat70</td>\n      <td>patch realms Loader server thrown classes load...</td>\n      <td>– Server ClassLoader not used for Server crea...</td>\n      <td>Created attachment 30931 [details]\\nproposed p...</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>340338</td>\n      <td>[org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...</td>\n      <td>eclipse.jdt.ui</td>\n      <td>invoking overwrites select select Ctrl charAtB...</td>\n      <td>– [content assist] Proposal does not replace ...</td>\n      <td>3.1.\\nInserting a proposal does not replace th...</td>\n    </tr>\n    <tr>\n      <th>457</th>\n      <td>21792</td>\n      <td>[org.eclipse.jdt.launching/launching/org/eclip...</td>\n      <td>eclipse.jdt.debug</td>\n      <td>argument Duser arguments passed argument dir e...</td>\n      <td>– vm arguments ending with a backslash cause ...</td>\n      <td>When creating a launch configuration, if one s...</td>\n    </tr>\n    <tr>\n      <th>1530</th>\n      <td>221019</td>\n      <td>[ui/org.eclipse.pde.core/src/org/eclipse/pde/i...</td>\n      <td>eclipse.pde.ui</td>\n      <td>bundle container entries Require Bug Bug class...</td>\n      <td>– Duplicated entries in classpath container</td>\n      <td>When a bundle is added as a Require-Bundle to ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:23.850488400Z",
     "start_time": "2023-07-23T14:44:23.810491900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1972, 6)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Works"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation Module"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precision', 'code_eval', 'roc_auc', 'cuad', 'xnli', 'rouge', 'pearsonr', 'mse', 'super_glue', 'comet', 'cer', 'sacrebleu', 'mahalanobis', 'wer', 'competition_math', 'f1', 'recall', 'coval', 'mauve', 'xtreme_s', 'bleurt', 'ter', 'accuracy', 'exact_match', 'indic_glue', 'spearmanr', 'mae', 'squad', 'chrf', 'glue', 'perplexity', 'mean_iou', 'squad_v2', 'meteor', 'bleu', 'wiki_split', 'sari', 'frugalscore', 'google_bleu', 'bertscore', 'matthews_correlation', 'seqeval', 'trec_eval', 'rl_reliability', 'angelina-wang/directional_bias_amplification', 'cpllab/syntaxgym', 'kaggle/ai4code', 'codeparrot/apps_metric', 'mfumanelli/geometric_mean', 'poseval', 'brier_score', 'abidlabs/mean_iou', 'abidlabs/mean_iou2', 'giulio98/codebleu', 'mase', 'mape', 'smape', 'dvitel/codebleu', 'NCSOFT/harim_plus', 'JP-SystemsX/nDCG', 'Drunper/metrica_tesi', 'jpxkqx/peak_signal_to_noise_ratio', 'jpxkqx/signal_to_reconstruction_error', 'hpi-dhc/FairEval', 'nist_mt', 'lvwerra/accuracy_score', 'character', 'charcut_mt', 'ybelkada/cocoevaluate', 'harshhpareek/bertscore', 'posicube/mean_reciprocal_rank', 'bstrai/classification_report', 'omidf/squad_precision_recall', 'Josh98/nl2bash_m', 'BucketHeadP65/confusion_matrix', 'BucketHeadP65/roc_curve', 'yonting/average_precision_score', 'transZ/test_parascore', 'transZ/sbert_cosine', 'hynky/sklearn_proxy', 'unnati/kendall_tau_distance', 'r_squared', 'Viona/fuzzy_reordering', 'Viona/kendall_tau', 'lhy/hamming_loss', 'lhy/ranking_loss', 'Muennighoff/code_eval_octopack', 'yuyijiong/quad_match_score', 'Splend1dchan/cosine_similarity', 'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics', 'Yeshwant123/mcc', 'transformersegmentation/segmentation_scores', 'sma2023/wil', 'chanelcolgate/average_precision', 'ckb/unigram', 'Felipehonorato/eer', 'manueldeprada/beer', 'tialaeMceryu/unigram', 'He-Xingwei/sari_metric', 'langdonholmes/cohen_weighted_kappa', 'fschlatt/ner_eval', 'hyperml/balanced_accuracy', 'brian920128/doc_retrieve_metrics', 'guydav/restrictedpython_code_eval', 'k4black/codebleu', 'Natooz/ece', 'ingyu/klue_mrc', 'Vipitis/shadermatch', 'unitxt/metric', 'gabeorlanski/bc_eval', 'mcnemar', 'exact_match', 'wilcoxon', 'kaleidophon/almost_stochastic_order', 'word_length', 'lvwerra/element_count', 'word_count', 'text_duplicates', 'perplexity', 'label_distribution', 'toxicity', 'regard', 'honest', 'ybelkada/toxicity', 'ronaldahmed/ccl_win', 'meg/perplexity', 'cakiki/tokens_per_byte', 'lsy641/distinct', 'vercontasta/ccl_win']\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from evaluate import load, list_evaluation_modules\n",
    "#list of metrics\n",
    "print(list_evaluation_modules())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:31.215125900Z",
     "start_time": "2023-07-23T14:44:26.453792400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "metric = load(\"bleu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:33.873901800Z",
     "start_time": "2023-07-23T14:44:32.955432200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluationModule(name: \"bleu\", module_type: \"metric\", features: [{'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}], usage: \"\"\"\n",
      "Computes BLEU score of translated segments against one or more references.\n",
      "Args:\n",
      "    predictions: list of translations to score.\n",
      "    references: list of lists of or just a list of references for each translation.\n",
      "    tokenizer : approach used for tokenizing `predictions` and `references`.\n",
      "        The default tokenizer is `tokenizer_13a`, a minimal tokenization approach that is equivalent to `mteval-v13a`, used by WMT.\n",
      "        This can be replaced by any function that takes a string as input and returns a list of tokens as output.\n",
      "    max_order: Maximum n-gram order to use when computing BLEU score.\n",
      "    smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
      "Returns:\n",
      "    'bleu': bleu score,\n",
      "    'precisions': geometric mean of n-gram precisions,\n",
      "    'brevity_penalty': brevity penalty,\n",
      "    'length_ratio': ratio of lengths,\n",
      "    'translation_length': translation_length,\n",
      "    'reference_length': reference_length\n",
      "Examples:\n",
      "\n",
      "    >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
      "    >>> references = [\n",
      "    ...     [\"hello there general kenobi\", \"hello there!\"],\n",
      "    ...     [\"foo bar foobar\"]\n",
      "    ... ]\n",
      "    >>> bleu = evaluate.load(\"bleu\")\n",
      "    >>> results = bleu.compute(predictions=predictions, references=references)\n",
      "    >>> print(results[\"bleu\"])\n",
      "    1.0\n",
      "\"\"\", stored examples: 0)\n"
     ]
    }
   ],
   "source": [
    "print(metric)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:35.296078900Z",
     "start_time": "2023-07-23T14:44:35.278078200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "{'bleu': 1.0,\n 'precisions': [1.0, 1.0, 1.0, 1.0],\n 'brevity_penalty': 1.0,\n 'length_ratio': 1.0,\n 'translation_length': 8,\n 'reference_length': 8}"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = [\"this is a test\", \"this is another test\"]\n",
    "test_true = [\"this is a test\", \"this is another test\"]\n",
    "metric.compute(predictions=test_pred, references=test_true)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:37.755957100Z",
     "start_time": "2023-07-23T14:44:36.648135600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### transofrmers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:44:39.105406700Z",
     "start_time": "2023-07-23T14:44:39.086402300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.31.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    Text2TextGenerationPipeline,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:45:07.505979300Z",
     "start_time": "2023-07-23T14:45:07.486984Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_checkpoint = \"ml6team/keyphrase-generation-t5-small-inspec\"\n",
    "model_checkpoint = \"ml6team/keyphrase-generation-t5-small-inspec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:45:09.426915900Z",
     "start_time": "2023-07-23T14:45:09.150232500Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:45:14.960052700Z",
     "start_time": "2023-07-23T14:45:14.946550700Z"
    }
   },
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\", \"Salesforce/codet5-small\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T14:45:17.670471100Z",
     "start_time": "2023-07-23T14:45:17.655957100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['bug_id', 'ground_truth', 'repo', 'reformed_query', 'bug_title',\n       'bug_description'],\n      dtype='object')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 20\n",
    "\n",
    "keyphrase_sep_token = ';'\n",
    "\n",
    "def preprocess_function(bug_description, reformed_query):\n",
    "    # Assuming you have the tokenizer initialized and named as 'tokenizer'\n",
    "\n",
    "    document_inputs = tokenizer(\n",
    "        bug_description,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_length,\n",
    "    )\n",
    "\n",
    "    keyphrases = reformed_query.split()\n",
    "\n",
    "    target_text = f\" {keyphrase_sep_token} \".join(keyphrases)\n",
    "    targets = tokenizer(\n",
    "        target_text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_target_length,\n",
    "        # return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "    )\n",
    "    labels = targets.input_ids  # Clone the input_ids tensor to create the labels\n",
    "    labels[labels == tokenizer.pad_token_id] = -100  # Set padding token to -100\n",
    "    labels = [label if label != tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "    model_inputs = {\n",
    "        \"input_ids\": document_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": document_inputs[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "    return model_inputs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T16:07:37.565769300Z",
     "start_time": "2023-07-23T16:07:37.550776200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:07:38.355894600Z",
     "start_time": "2023-07-23T16:07:38.317896800Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_df = train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:07:39.131832200Z",
     "start_time": "2023-07-23T16:07:39.102834400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      bug_id                                       ground_truth  \\\n2288   58110  [java/org/apache/jasper/compiler/ErrorDispatch...   \n2208   55656  [java/org/apache/catalina/startup/Catalina.jav...   \n1036  340338  [org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...   \n\n                repo                                     reformed_query  \\\n2288        tomcat70  UTF JDT Wrapper JspCompilationContext size Def...   \n2208        tomcat70  patch realms Loader server thrown classes load...   \n1036  eclipse.jdt.ui  invoking overwrites select select Ctrl charAtB...   \n\n                                              bug_title  \\\n2288   – JSP compiler points error to wrong line num...   \n2208   – Server ClassLoader not used for Server crea...   \n1036   – [content assist] Proposal does not replace ...   \n\n                                        bug_description  \n2288  Created attachment 32888 [details]\\nApache Tom...  \n2208  Created attachment 30931 [details]\\nproposed p...  \n1036  3.1.\\nInserting a proposal does not replace th...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bug_id</th>\n      <th>ground_truth</th>\n      <th>repo</th>\n      <th>reformed_query</th>\n      <th>bug_title</th>\n      <th>bug_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2288</th>\n      <td>58110</td>\n      <td>[java/org/apache/jasper/compiler/ErrorDispatch...</td>\n      <td>tomcat70</td>\n      <td>UTF JDT Wrapper JspCompilationContext size Def...</td>\n      <td>– JSP compiler points error to wrong line num...</td>\n      <td>Created attachment 32888 [details]\\nApache Tom...</td>\n    </tr>\n    <tr>\n      <th>2208</th>\n      <td>55656</td>\n      <td>[java/org/apache/catalina/startup/Catalina.jav...</td>\n      <td>tomcat70</td>\n      <td>patch realms Loader server thrown classes load...</td>\n      <td>– Server ClassLoader not used for Server crea...</td>\n      <td>Created attachment 30931 [details]\\nproposed p...</td>\n    </tr>\n    <tr>\n      <th>1036</th>\n      <td>340338</td>\n      <td>[org.eclipse.jdt.ui/ui/org/eclipse/jdt/interna...</td>\n      <td>eclipse.jdt.ui</td>\n      <td>invoking overwrites select select Ctrl charAtB...</td>\n      <td>– [content assist] Proposal does not replace ...</td>\n      <td>3.1.\\nInserting a proposal does not replace th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:07:41.163699900Z",
     "start_time": "2023-07-23T16:07:41.144186100Z"
    }
   },
   "outputs": [],
   "source": [
    "sr = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in temp_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T15:10:54.042274400Z",
     "start_time": "2023-07-23T15:10:54.023674600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T15:15:39.541167700Z",
     "start_time": "2023-07-23T15:15:39.518857800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_ids': [6357, 26, 11352, 3538, 10927, 784, 221, 5756, 7, 908, 24263, 3059, 2138, 834, 26346, 5, 4241, 3, 18, 848, 52, 127, 934, 5, 10500, 27, 15687, 12, 9268, 8, 336, 1205, 96, 121, 2493, 6, 11, 446, 4274, 2890, 699, 500, 3505, 12, 689, 381, 1713, 927, 84, 19, 337, 38, 8, 336, 1205, 2493, 5, 3636, 10, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 3, 2, 1454, 1741, 543, 543, 8532, 9886, 2423, 31, 6675, 371, 6039, 31, 738, 25160, 2423, 31, 6327, 87, 10500, 31, 1454, 3155, 3, 2, 1454, 1741, 543, 4830, 3274, 3, 31, 27578, 5, 13780, 5, 1935, 31, 3, 1454, 3155, 3, 2, 1454, 55, 22341, 794, 41, 61, 3, 2, 6792, 2, 17057, 3155, 570, 17057, 21486, 15, 7, 3274, 206, 195, 117, 3, 99, 41, 3350, 17057, 21486, 15, 7, 2423, 2423, 29, 83, 40, 1820, 9175, 570, 17057, 21486, 15, 7, 5, 7991, 9960, 2423, 2423, 632, 61, 1205, 96, 121, 117, 22341, 3, 7, 29979, 196, 1018, 371, 699, 3274, 206, 195, 117, 21, 41, 17057, 3735, 21486, 3, 10, 570, 17057, 21486, 15, 7, 61, 3, 2, 13751, 7, 29979, 196, 1018, 371, 699, 3274, 96, 6645, 18, 25982, 63, 18, 30536, 21486, 18, 121, 1768, 41, 11500, 53, 61, 30536, 21486, 1768, 96, 5, 102, 1725, 121, 117, 3, 2, 3, 12840, 109, 152, 19, 29979, 196, 1018, 371, 699, 5420, 343, 3274, 6136, 117, 3, 99, 41, 55, 41, 7, 29979, 196, 1018, 371, 699, 2423, 2423, 29, 83, 40, 1820, 9175, 3, 7, 29979, 196, 1018, 371, 699, 5, 159, 427, 1167, 17, 63, 9960, 61, 61, 3, 2, 3, 7, 29979, 196, 1018, 371, 699, 3274, 96, 8221, 7, 87, 121, 1768, 3, 7, 29979, 196, 1018, 371, 699, 117, 13751, 371, 699, 1042, 29979, 196, 1018, 3274, 126, 7344, 41, 12251, 5, 2782, 1649, 138, 345, 9, 189, 41, 7, 29979, 196, 1018, 371, 699, 61, 3670, 13751, 159, 29979, 196, 1018, 371, 699, 5420, 343, 3274, 1042, 29979, 196, 1018, 5, 12135, 7, 41, 3670, 3, 2, 1205, 41, 7, 29979, 196, 1018, 371, 699, 2423, 2423, 29, 83, 40, 1820, 9175, 3, 7, 29979, 196, 1018, 371, 699, 5, 159, 427, 1167, 17, 63, 9960, 61, 3, 58, 96, 121, 3, 10, 96, 2, 603, 122, 3, 7, 52, 75, 2423, 31, 121, 1768, 3, 7, 29979, 196, 1018, 371, 699, 1768, 96, 31, 87, 3155, 121, 117, 1205, 96, 121, 117, 13751, 100, 2493, 756, 56, 1137, 12, 51, 2138, 446, 12111, 29801, 500, 3505, 12, 689, 1713, 927, 2, 3378, 2, 299, 3, 99, 888, 48, 689, 139, 8, 756, 689, 6, 258, 29801, 56, 500, 3505, 12, 8, 269, 689, 381, 1713, 2773, 3, 2, 3, 1454, 3155, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 446, 4274, 2890, 699, 5763, 3, 14817, 14817, 18, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 14817, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 683, 9, 4339, 26586, 10, 597, 179, 12, 2890, 699, 853, 21, 446, 4274, 10, 389, 3505, 6935, 44, 689, 10, 505, 16, 8, 3, 354, 7, 102, 1042, 10, 3, 87, 4377, 5, 354, 7, 102, 597, 60, 1836, 179, 1081, 305, 10, 3, 2, 431, 10, 6792, 2, 17057, 3155, 570, 17057, 21486, 15, 7, 3274, 206, 195, 117, 489, 10, 3, 99, 41, 3350, 17057, 21486, 15, 7, 2423, 2423, 29, 83, 40, 1820, 9175, 570, 17057, 21486, 15, 7, 5, 7991, 9960, 2423, 2423, 632, 61, 505, 10, 1205, 96, 536, 121, 117, 668, 10, 335, 10, 22341, 3, 7, 29979, 196, 1018, 371, 699, 3274, 206, 195, 117, 850, 10, 21, 41, 17057, 3735, 21486, 3, 10, 570, 17057, 21486, 15, 7, 61, 3, 19814, 6471, 15, 10, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 29509, 10575, 52, 127, 566, 232, 1171, 5, 27578, 75, 10575, 52, 127, 599, 29509, 10575, 52, 127, 566, 232, 1171, 5, 27578, 10, 17864, 61, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 10575, 52, 127, 23664, 144, 1703, 5, 27578, 75, 10575, 52, 127, 599, 10575, 52, 127, 23664, 144, 1703, 5, 27578, 10, 3420, 10938, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 683, 12111, 5890, 102, 173, 49, 5, 729, 49, 342, 21486, 599, 683, 12111, 5890, 102, 173, 49, 5, 27578, 10, 3707, 9120, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 4118, 11728, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 2469, 7256, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 7699, 173, 49, 5, 5890, 102, 173, 49, 5, 7699, 699, 599, 5890, 102, 173, 49, 5, 27578, 10, 3710, 6982, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 683, 7, 102, 5890, 102, 173, 257, 4302, 6327, 5, 7699, 699, 599, 683, 7, 102, 5890, 102, 173, 257, 4302, 6327, 5, 27578, 10, 4122, 12703, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 3473, 1655, 5, 683, 7, 102, 17598, 1655, 518, 5846, 883, 5, 5114, 599, 683, 7, 102, 17598, 1655, 518, 5846, 883, 5, 27578, 10, 2469, 12703, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 3473, 1655, 5, 683, 7, 102, 17598, 1655, 5, 5114, 683, 7, 102, 371, 699, 599, 683, 7, 102, 17598, 1655, 5, 27578, 10, 3288, 9120, 3, 1677, 5, 9750, 1033, 5, 1191, 4339, 5, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 9164, 446, 12111, 22553, 883, 446, 7, 102, 5890, 102, 173, 257, 4302, 6327, 812, 3, 29509, 10575, 1]}, {'input_ids': [6357, 26, 11352, 604, 4271, 536, 784, 221, 5756, 7, 908, 4382, 7947, 366, 975, 18765, 2460, 5, 7134, 49, 16, 1712, 9, 8280, 5, 10401, 49, 3010, 28, 12256, 3, 6443, 9522, 7, 42, 15854, 7, 11, 70, 6002, 11573, 6, 3, 99, 273, 2287, 33, 356, 16, 2460, 5, 226, 51, 40, 3, 9, 3, 10077, 6392, 19, 3, 12618, 5, 37, 1053, 19, 18759, 222, 49, 338, 5150, 17598, 49, 31, 7, 4501, 434, 32, 9, 588, 11, 59, 2625, 4501, 434, 32, 9, 588, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, 15854, 7, 1815, 9, 588, 2460, 3, 12618, 2287, 4002, 49, 11352, 4002, 49, 18759, 222, 49, 1, 0]}, {'input_ids': [3, 18495, 5, 28953, 53, 3, 9, 6384, 405, 59, 3601, 8, 1374, 2850, 3, 99, 132, 31, 7, 3, 9, 1801, 116, 16, 1621, 1765, 738, 2094, 5, 2300, 6320, 10, 1300, 356, 3, 31, 5890, 4788, 1575, 147, 17504, 7, 31, 1682, 43, 10, 3, 14817, 1454, 2, 14817, 3, 12186, 794, 9960, 3, 2, 22341, 3, 7, 117, 3, 7, 5, 2782, 279, 63, 1422, 9960, 117, 3, 2, 3, 14817, 1454, 2, 14817, 1877, 1738, 96, 2782, 121, 2853, 205, 17, 52, 40, 1220, 24722, 3594, 1738, 3, 31, 4059, 188, 17, 31, 11, 8722, 34, 3274, 15425, 3, 7, 5, 4059, 188, 17, 279, 63, 1422, 9960, 117, 262, 4, 345, 14196, 2326, 10, 3, 7, 5, 4059, 188, 17, 9960, 117, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [-100, 1621, 1765, 147, 17504, 7, 1738, 1738, 205, 17, 52, 40, 3, 4059, 188, 17, 279, 63, 1422, 1]}]\n"
     ]
    }
   ],
   "source": [
    "print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "train_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in train_df.iterrows()]\n",
    "test_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in test_df.iterrows()]\n",
    "valid_data = [preprocess_function(row[\"bug_description\"], row[\"reformed_query\"]) for _, row in valid_df.iterrows()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:14.224137500Z",
     "start_time": "2023-07-23T16:12:11.213115800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "tokenized_datasets = {\n",
    "    'train': train_data,\n",
    "    'test': test_data,\n",
    "    'validation': valid_data\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:14.274117100Z",
     "start_time": "2023-07-23T16:12:14.224137500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:18.150654Z",
     "start_time": "2023-07-23T16:12:17.265288700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:19.462065900Z",
     "start_time": "2023-07-23T16:12:19.419532900Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Adjust the batch size based on available GPU memory\n",
    "batch_size = 16\n",
    "\n",
    "# Set up the Seq2SeqTrainingArguments\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-T5_keyphrase\",  # Change the output directory name\n",
    "    learning_rate=2e-5,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    # push_to_hub=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:21.432056400Z",
     "start_time": "2023-07-23T16:12:21.407209Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    # Note that other metrics may not have a `use_aggregator` parameter\n",
    "    # and thus will return a list, computing a metric for each sentence.\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    # Extract a few results\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "\n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:24.802398600Z",
     "start_time": "2023-07-23T16:12:24.792400600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T16:12:27.141312400Z",
     "start_time": "2023-07-23T16:12:26.941127900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/124 : < :, Epoch 0.01/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "type list doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[80], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer.py:1539\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1534\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m   1536\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[0;32m   1537\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[0;32m   1538\u001B[0m )\n\u001B[1;32m-> 1539\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1540\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1541\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1542\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1544\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer.py:1916\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   1913\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_training_stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1915\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_epoch_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m-> 1916\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m DebugOption\u001B[38;5;241m.\u001B[39mTPU_METRICS_DEBUG \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdebug:\n\u001B[0;32m   1919\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_torch_tpu_available():\n\u001B[0;32m   1920\u001B[0m         \u001B[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer.py:2226\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2224\u001B[0m         metrics\u001B[38;5;241m.\u001B[39mupdate(dataset_metrics)\n\u001B[0;32m   2225\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2226\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2227\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step, metrics)\n\u001B[0;32m   2229\u001B[0m \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer_seq2seq.py:159\u001B[0m, in \u001B[0;36mSeq2SeqTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m gen_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_beams\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    155\u001B[0m     gen_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_beams\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m gen_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_beams\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgeneration_num_beams\n\u001B[0;32m    156\u001B[0m )\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gen_kwargs \u001B[38;5;241m=\u001B[39m gen_kwargs\n\u001B[1;32m--> 159\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer.py:2934\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   2931\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   2933\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[1;32m-> 2934\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2935\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2936\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2937\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[0;32m   2938\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[0;32m   2939\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   2940\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2941\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2942\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2944\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[0;32m   2945\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer.py:3222\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3218\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics(\n\u001B[0;32m   3219\u001B[0m             EvalPrediction(predictions\u001B[38;5;241m=\u001B[39mall_preds, label_ids\u001B[38;5;241m=\u001B[39mall_labels, inputs\u001B[38;5;241m=\u001B[39mall_inputs)\n\u001B[0;32m   3220\u001B[0m         )\n\u001B[0;32m   3221\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3222\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3223\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3224\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[1;32mIn[78], line 25\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[1;34m(eval_pred)\u001B[0m\n\u001B[0;32m     22\u001B[0m prediction_lens \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mcount_nonzero(pred \u001B[38;5;241m!=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad_token_id) \u001B[38;5;28;01mfor\u001B[39;00m pred \u001B[38;5;129;01min\u001B[39;00m predictions]\n\u001B[0;32m     23\u001B[0m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgen_len\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(prediction_lens)\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {k: \u001B[38;5;28mround\u001B[39m(v, \u001B[38;5;241m4\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m result\u001B[38;5;241m.\u001B[39mitems()}\n",
      "Cell \u001B[1;32mIn[78], line 25\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     22\u001B[0m prediction_lens \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mcount_nonzero(pred \u001B[38;5;241m!=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad_token_id) \u001B[38;5;28;01mfor\u001B[39;00m pred \u001B[38;5;129;01min\u001B[39;00m predictions]\n\u001B[0;32m     23\u001B[0m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgen_len\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(prediction_lens)\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {k: \u001B[38;5;28;43mround\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m result\u001B[38;5;241m.\u001B[39mitems()}\n",
      "\u001B[1;31mTypeError\u001B[0m: type list doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T16:47:17.545900700Z",
     "start_time": "2023-07-23T16:12:28.864958200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "#\n",
    "# # Initialize tqdm progress bar\n",
    "# progress_bar = tqdm(total=training_args.num_train_epochs, desc=\"Epoch\")\n",
    "#\n",
    "# # Train the model with tqdm progress bar\n",
    "# for epoch in range(training_args.num_train_epochs):\n",
    "#     trainer.train()\n",
    "#     progress_bar.update(1)\n",
    "#\n",
    "# # Close the tqdm progress bar\n",
    "# progress_bar.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(\"Training Losses:\", train_results.training_loss)\n",
    "# print(\"Evaluation Metrics:\", train_results.metrics)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "output_directory = \"../FineTunedModels/T5_keyphrase\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T19:48:58.243745500Z",
     "start_time": "2023-07-22T19:48:58.217102600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the trained model and configuration\n",
    "trainer.save_model(output_directory)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(output_directory)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T19:49:22.337628700Z",
     "start_time": "2023-07-22T19:49:21.058187500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate with test data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AcceleratorState' object has no attribute 'distributed_type'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[55], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the test dataset\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m test_results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenized_datasets\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtest\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer_seq2seq.py:159\u001B[0m, in \u001B[0;36mSeq2SeqTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001B[0m\n\u001B[0;32m    154\u001B[0m gen_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_beams\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    155\u001B[0m     gen_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_beams\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m gen_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_beams\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mgeneration_num_beams\n\u001B[0;32m    156\u001B[0m )\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gen_kwargs \u001B[38;5;241m=\u001B[39m gen_kwargs\n\u001B[1;32m--> 159\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer.py:2930\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   2927\u001B[0m \u001B[38;5;66;03m# memory metrics - must set up as early as possible\u001B[39;00m\n\u001B[0;32m   2928\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory_tracker\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m-> 2930\u001B[0m eval_dataloader \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_eval_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2931\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   2933\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\trainer.py:910\u001B[0m, in \u001B[0;36mTrainer.get_eval_dataloader\u001B[1;34m(self, eval_dataset)\u001B[0m\n\u001B[0;32m    907\u001B[0m     dataloader_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msampler\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_eval_sampler(eval_dataset)\n\u001B[0;32m    908\u001B[0m     dataloader_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdrop_last\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdataloader_drop_last\n\u001B[1;32m--> 910\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprepare\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdataloader_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\accelerate\\accelerator.py:1142\u001B[0m, in \u001B[0;36mAccelerator.prepare\u001B[1;34m(self, device_placement, *args)\u001B[0m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(device_placement) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(args):\n\u001B[0;32m   1138\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1139\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`device_placement` should be a list with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(args)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m elements (the number of objects passed).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1140\u001B[0m     )\n\u001B[1;32m-> 1142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistributed_type\u001B[49m \u001B[38;5;241m==\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mFSDP:\n\u001B[0;32m   1143\u001B[0m     model_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1144\u001B[0m     optimizer_present \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\accelerate\\accelerator.py:468\u001B[0m, in \u001B[0;36mAccelerator.distributed_type\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdistributed_type\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 468\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistributed_type\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'AcceleratorState' object has no attribute 'distributed_type'"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_results = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T19:49:25.676062100Z",
     "start_time": "2023-07-22T19:49:24.885278200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# see output with test data\n",
    "print(\"Evaluation Metrics:\", test_results.metrics)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[86], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Assuming 'text' is a string, convert it to a list to use the generator\u001B[39;00m\n\u001B[0;32m      8\u001B[0m text \u001B[38;5;241m=\u001B[39m test_df\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbug_description\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m----> 9\u001B[0m keyphrases \u001B[38;5;241m=\u001B[39m \u001B[43mgenerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Convert 'text' to a list and pass it to the generator\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(keyphrases)\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:165\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    137\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;124;03m    Generate the output text(s) using text(s) given as inputs.\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;124;03m          ids of the generated text.\u001B[39;00m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 165\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    167\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mlist\u001B[39m)\n\u001B[0;32m    168\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(el, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m el \u001B[38;5;129;01min\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m    169\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28mlen\u001B[39m(res) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result)\n\u001B[0;32m    170\u001B[0m     ):\n\u001B[0;32m    171\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m result]\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\pipelines\\base.py:1103\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m can_use_iterator:\n\u001B[0;32m   1100\u001B[0m     final_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   1101\u001B[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001B[0;32m   1102\u001B[0m     )\n\u001B[1;32m-> 1103\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfinal_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n\u001B[0;32m   1105\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001B[0m, in \u001B[0;36mPipelineIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader_batch_item()\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[1;32m--> 124\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    125\u001B[0m processed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfer(item, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams)\n\u001B[0;32m    126\u001B[0m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001B[0m, in \u001B[0;36mPipelineIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[0;32m    124\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterator)\n\u001B[1;32m--> 125\u001B[0m processed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfer(item, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams)\n\u001B[0;32m    126\u001B[0m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader_batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;66;03m# Try to infer the size of the batch\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\pipelines\\base.py:1028\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[1;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[0;32m   1026\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[0;32m   1027\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m-> 1028\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[0;32m   1029\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1030\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\pipelines\\text2text_generation.py:187\u001B[0m, in \u001B[0;36mText2TextGenerationPipeline._forward\u001B[1;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[0;32m    185\u001B[0m generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m generate_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmax_length)\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_inputs(input_length, generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin_length\u001B[39m\u001B[38;5;124m\"\u001B[39m], generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m--> 187\u001B[0m output_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mgenerate_kwargs)\n\u001B[0;32m    188\u001B[0m out_b \u001B[38;5;241m=\u001B[39m output_ids\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\generation\\utils.py:1345\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001B[0m\n\u001B[0;32m   1337\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\n\u001B[0;32m   1338\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1339\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration results, please set `padding_side=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m` when initializing the tokenizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1340\u001B[0m         )\n\u001B[0;32m   1342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m model_kwargs:\n\u001B[0;32m   1343\u001B[0m     \u001B[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001B[39;00m\n\u001B[0;32m   1344\u001B[0m     \u001B[38;5;66;03m# and added to `model_kwargs`\u001B[39;00m\n\u001B[1;32m-> 1345\u001B[0m     model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_encoder_decoder_kwargs_for_generation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1346\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_input_name\u001B[49m\n\u001B[0;32m   1347\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1349\u001B[0m \u001B[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001B[39;00m\n\u001B[0;32m   1350\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder:\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\generation\\utils.py:644\u001B[0m, in \u001B[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001B[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001B[0m\n\u001B[0;32m    642\u001B[0m encoder_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    643\u001B[0m encoder_kwargs[model_input_name] \u001B[38;5;241m=\u001B[39m inputs_tensor\n\u001B[1;32m--> 644\u001B[0m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_outputs\u001B[39m\u001B[38;5;124m\"\u001B[39m]: ModelOutput \u001B[38;5;241m=\u001B[39m encoder(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mencoder_kwargs)\n\u001B[0;32m    646\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_kwargs\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:992\u001B[0m, in \u001B[0;36mT5Stack.forward\u001B[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    990\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_tokens \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    991\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have to initialize the model with valid token embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 992\u001B[0m     inputs_embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_tokens\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    994\u001B[0m batch_size, seq_length \u001B[38;5;241m=\u001B[39m input_shape\n\u001B[0;32m    996\u001B[0m \u001B[38;5;66;03m# required mask seq length can be calculated via length of past\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:162\u001B[0m, in \u001B[0;36mEmbedding.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 162\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    163\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnorm_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Research\\Coding\\QueryReformulation_T5\\VirtualEnv\\lib\\site-packages\\torch\\nn\\functional.py:2210\u001B[0m, in \u001B[0;36membedding\u001B[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[0;32m   2204\u001B[0m     \u001B[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001B[39;00m\n\u001B[0;32m   2205\u001B[0m     \u001B[38;5;66;03m# XXX: equivalent to\u001B[39;00m\n\u001B[0;32m   2206\u001B[0m     \u001B[38;5;66;03m# with torch.no_grad():\u001B[39;00m\n\u001B[0;32m   2207\u001B[0m     \u001B[38;5;66;03m#   torch.embedding_renorm_\u001B[39;00m\n\u001B[0;32m   2208\u001B[0m     \u001B[38;5;66;03m# remove once script supports set_grad_enabled\u001B[39;00m\n\u001B[0;32m   2209\u001B[0m     _no_grad_embedding_renorm_(weight, \u001B[38;5;28minput\u001B[39m, max_norm, norm_type)\n\u001B[1;32m-> 2210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_grad_by_freq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "# Assuming you have a CUDA-capable device, check if it's available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Assuming 'text' is a string, convert it to a list to use the generator\n",
    "text = test_df.iloc[1][\"bug_description\"]\n",
    "keyphrases = generator([text])  # Convert 'text' to a list and pass it to the generator\n",
    "\n",
    "print(keyphrases)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T16:58:14.012537Z",
     "start_time": "2023-07-23T16:58:13.785175500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print type analyzeCode Local expressions missing compiler System lambda\n"
     ]
    }
   ],
   "source": [
    "# print the actual output\n",
    "print(test_df.iloc[0][\"reformed_query\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T19:54:35.199372800Z",
     "start_time": "2023-07-22T19:54:35.177538300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch applicationcontextfacade ; type safety ; unchecked cast \n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "# Move the input tensor to the CPU\n",
    "input_ids = tokenizer(test_df.iloc[1][\"bug_description\"], return_tensors=\"pt\").input_ids.to('cpu')\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(input_ids, max_length=20, num_beams=10, early_stopping=True, top_k=50, num_return_sequences=5)\n",
    "\n",
    "# Decode and print the output\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T17:04:35.675107700Z",
     "start_time": "2023-07-23T17:04:34.841607Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
